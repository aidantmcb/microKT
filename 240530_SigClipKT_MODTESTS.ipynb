{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool\n",
    "import multiprocessing as mp\n",
    "import os\n",
    "os.environ['OMP_NUM_THREADS'] = \"1\"\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import astropy.units as u  \n",
    "import astropy.constants as c\n",
    "from astropy.coordinates import SkyCoord\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import Normalize\n",
    "import matplotlib \n",
    "\n",
    "from astropy.io import fits\n",
    "from astropy.table import Table, join\n",
    "from astropy.wcs import WCS\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "from dustmaps.vergely2022 import Vergely2022Query\n",
    "from dustmaps.edenhofer2023 import Edenhofer2023Query\n",
    "\n",
    "import pickle \n",
    "import sys\n",
    "import os\n",
    "import tqdm\n",
    "import datetime\n",
    "\n",
    "import emcee\n",
    "import corner\n",
    "\n",
    "import h5py\n",
    "import multiprocessing as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import globalvars\n",
    "dust_data = globalvars.DustData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_fname = '/uufs/astro.utah.edu/common/home/u1371365/DIB_KT_CACloud/edenhofer_out.h5'\n",
    "\n",
    "with h5py.File(map_fname, 'r') as f:\n",
    "    edenhofer = np.array(f['data'])\n",
    "    dust_data.intake_map(edenhofer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from specfns import get_wavs, resample_interp, dopplershift, lambda0, sigma0\n",
    "from filehandling import get_ca_res, get_madgics_res, get_medres\n",
    "from spacefns_v2 import select_stars, find_nearest, find_radius, differentialAmplitude\n",
    "from MCMCfns import logprob_2\n",
    "from sightline import Sightline\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CA_meta = Table(fits.open('../Data/230420_CAResiduals/CA_meta.fits')[1].data)\n",
    "CAresdir = '/uufs/astro.utah.edu/common/home/u1371365/Data/230420_CAResiduals/'\n",
    "CAMADGICSresdir = '/uufs/astro.utah.edu/common/home/u1371365/Data/230829_MADGICSResiduals/'\n",
    "starhorsepath = '/uufs/chpc.utah.edu/common/home/sdss/dr17/env/APOGEE_STARHORSE/APOGEE_DR17_EDR3_STARHORSE_v2.fits'\n",
    "starhorse = Table.read(starhorsepath, hdu = 1)\n",
    "starhorse = starhorse['APOGEE_ID', 'dist16', 'dist50', 'dist84', 'AV16', 'AV50', 'AV84']\n",
    "\n",
    "CA_meta = join(CA_meta, starhorse, keys = 'APOGEE_ID', join_type = 'left')\n",
    "\n",
    "CA_meta_full = CA_meta.copy()\n",
    "\n",
    "with open('/uufs/astro.utah.edu/common/home/u1371365/DIB_KT_CACloud/goodbad.pickle', mode = 'rb') as f:\n",
    "    goodbad = pickle.load(f)\n",
    "\n",
    "# added 02.01\n",
    "data_criteria = (((CA_meta['SNR'] > 80) & (CA_meta['TEFF'] > 5000)) | (CA_meta['SNR'] > 150)) & (CA_meta['ASPCAP_CHI2_1'] > 1) & (CA_meta['ASPCAP_CHI2_1'] < 5)\n",
    "print(np.sum(data_criteria))\n",
    "CA_meta= CA_meta[data_criteria]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wavs = get_wavs()\n",
    "window = (wavs > lambda0 -10) & (wavs < lambda0 + 10)\n",
    "wavs_window = wavs[window]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = 2.5 # x downsampled\n",
    "rad = 0.23\n",
    "sample_dim_l = np.linspace(159, 167, int(8 / (ds * rad)))\n",
    "sample_dim_b = np.linspace(-12.5 , -4.5, int(8 / (ds * rad)))\n",
    "sample_grid_l, sample_grid_b = np.meshgrid(sample_dim_l, sample_dim_b)\n",
    "grid_map_inds = np.array([find_nearest(sample_grid_l.flatten()[i], sample_grid_b.flatten()[i]) for i in range(len(sample_grid_l.flatten()))]).T\n",
    "grid_map = np.nansum(np.copy(edenhofer[grid_map_inds[1], grid_map_inds[0], :]).reshape(*sample_grid_l.shape, -1), axis = 2)\n",
    "grid_Nstar = np.array([np.nansum((np.abs((sample_grid_l.flatten()[i] - CA_meta['GLON'])) <= rad) & \n",
    "            (np.abs((sample_grid_b.flatten()[i] - CA_meta['GLAT'])) <= rad)) for i in range(len(sample_grid_l.flatten()))]).reshape(*sample_grid_l.shape)\n",
    "\n",
    "filament_l = (159, 169)\n",
    "filament_b = (-10, -6)\n",
    "\n",
    "N_min = 5\n",
    "radius_min = np.zeros(sample_grid_l.shape)\n",
    "mgrid = np.mgrid[0:len(sample_dim_l), 0:len(sample_dim_b)]\n",
    "for i in mgrid[0].flatten():\n",
    "    for j in mgrid[1].flatten():\n",
    "        radius_min[i, j] = find_radius(sample_grid_l[i, j], sample_grid_b[i, j], N_min, CA_meta)\n",
    "        radius_min[i, j] = np.max([radius_min[i, j], 0.23])\n",
    "\n",
    "radius_max = 0.4\n",
    "print(np.nansum(radius_min < radius_max))\n",
    "\n",
    "\n",
    "crit_filament = ((sample_grid_l > filament_l[0]) & (sample_grid_l < filament_l[1]) & \n",
    "                 (sample_grid_b > filament_b[0]) & (sample_grid_b < filament_b[1]) &\n",
    "                 (grid_map > 2.2) & (radius_min < 0.5)) #(grid_Nstar > 5) & (grid_Nstar <= 10))\n",
    "\n",
    "crit_background =  (((sample_grid_l <= filament_l[0]) | (sample_grid_l >= filament_l[1]) |\n",
    "                 (sample_grid_b <= filament_b[0]) | (sample_grid_b >= filament_b[1])) &\n",
    "                 (grid_map <= 1.5) & (radius_min < radius_max)) #(grid_Nstar > 5) & (grid_Nstar <= 10))\n",
    "\n",
    "# crit_coverage = (np.sum() => 1 & )\n",
    "\n",
    "N_filament = np.sum(crit_filament)\n",
    "N_background = np.sum(crit_background)\n",
    "print(np.sum(crit_filament))\n",
    "print(np.sum(crit_background))\n",
    "l_fil, b_fil, AV_fil = (sample_grid_l[crit_filament].flatten(), sample_grid_b[crit_filament].flatten(),\n",
    "                        grid_map[crit_filament].flatten())\n",
    "l_off, b_off, AV_off = (sample_grid_l[crit_background].flatten(), sample_grid_b[crit_background].flatten(),\n",
    "                        grid_map[crit_background].flatten())\n",
    "\n",
    "l_sample, b_sample, AV_sample = (np.concatenate([l_fil, l_off]), np.concatenate([b_fil, b_off]),\n",
    "                                  np.concatenate([AV_fil, AV_off]))\n",
    "radius_min_fil = radius_min[crit_filament].flatten()\n",
    "radius_min_off = radius_min[crit_background].flatten()\n",
    "radius_sample = np.concatenate([radius_min_fil, radius_min_off])\n",
    "\n",
    "selected_inds = []\n",
    "for i in range(len(l_sample)):\n",
    "    l_center, b_center = l_sample[i], b_sample[i]\n",
    "    rad_i = radius_sample[i]\n",
    "    selection = select_stars(CA_meta, l_center, b_center, radius = rad_i)\n",
    "    # print(len(selection))\n",
    "    selected_inds.append(selection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dibfn = lambda x, mu, sigma, a: 1-a * np.exp(-0.5 * (x - mu)**2 / sigma**2)\n",
    "def sigma_clip_mask(y, x = wavs, k = 2.5):\n",
    "    y_over_gauss = None\n",
    "\n",
    "    try:\n",
    "        gaussfit = curve_fit(dibfn, x[window], y[window].filled(np.nan), p0 = (15272, 1.2, 0.05), bounds = ([15269, 0.5, 0], [15275, 2, 0.15]), check_finite = False, nan_policy = 'omit')\n",
    "\n",
    "    except:\n",
    "        # gaussfit = ((15272, 1.2, 0.05),())\n",
    "        print('fail')\n",
    "        return None, None\n",
    "    #     y_over_gauss = None\n",
    "    #     gaussfit = ((15272, 1.2, 0.05),())\n",
    "    #     # fit = dibfn(x, 15272.42, 1.2, 0.05)\n",
    "    #     # y_over_gauss = y / fit\n",
    "    #     print('POOR GAUSS FIT IN SIGMA CLIP')\n",
    "    y_over_gauss = y / dibfn(x, *gaussfit[0])\n",
    "\n",
    "    med = np.nanmedian(y_over_gauss[window])\n",
    "    stdev = np.std(y_over_gauss[window], ddof = 1)\n",
    "    mask = np.abs(y_over_gauss - med) > k * stdev\n",
    "    mask = mask + np.roll(mask, -1) + np.roll(mask, -1)\n",
    "    mask = mask.astype(bool)\n",
    "    return mask, stdev\n",
    "\n",
    "def sigmaClip(y, yerr,k=2.5):\n",
    "    clip = True\n",
    "    clip_iters = 0\n",
    "    std = np.nanstd(y[window], ddof = 1)\n",
    "    mask = np.zeros(y.shape).astype(bool)\n",
    "    clip_success = True\n",
    "\n",
    "    while clip:\n",
    "        clip_mask, std_clipped = sigma_clip_mask(np.ma.array(y, mask = mask.copy()), k = k)\n",
    "        if clip_mask is None:\n",
    "            clip_success = False\n",
    "            return mask, clip_success\n",
    "        clip_mask = clip_mask.filled(False)\n",
    "\n",
    "        if std - std_clipped  < 1e-4:\n",
    "            clip = False\n",
    "\n",
    "\n",
    "        else:\n",
    "            clip_iters += 1\n",
    "            std = std_clipped\n",
    "            mask = mask + clip_mask\n",
    "\n",
    "    return mask, clip_success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathCO = '/uufs/astro.utah.edu/common/home/u1371365/Data/Temporary/Catalogs/DHT21_Taurus_interp.fits'\n",
    "hdulCO = fits.open(pathCO)\n",
    "\n",
    "headerCO = hdulCO[0].header\n",
    "dataCO = hdulCO[0].data\n",
    "wcsCO = WCS(headerCO)\n",
    "\n",
    "glon = headerCO['CRVAL2'] + headerCO['CDELT2'] * (np.arange(0, headerCO['NAXIS2'])- headerCO['CRPIX2'])\n",
    "glat = headerCO['CRVAL3'] + headerCO['CDELT3'] * (np.arange(0, headerCO['NAXIS3'])- headerCO['CRPIX3'])\n",
    "rvel = headerCO['CRVAL1'] + headerCO['CDELT1'] * (np.arange(0, headerCO['NAXIS1'])- headerCO['CRPIX1'])\n",
    "\n",
    "l, b, v = np.meshgrid(glon, glat, rvel)\n",
    "coord = SkyCoord(l * u.deg, b  * u.deg, radial_velocity = v * u.km/u.s, pm_l_cosb = 0 * u.deg/u.s,\n",
    "                  pm_b = 0 * u.deg /u.s, distance = 500 * u.pc, frame = 'galacticlsr')\n",
    "\n",
    "coord_icrs = coord.transform_to('icrs')\n",
    "\n",
    "def get_CO_profile(l, b):\n",
    "    coord_sel = SkyCoord(l = l * u.deg, b = b * u.deg, frame = 'galactic')\n",
    "    pix_ind_l, pix_ind_b = wcsCO.world_to_pixel(0 * u.km/u.s, coord_sel)[1:]\n",
    "    CO_profile = dataCO.T[:, int(pix_ind_l), int(pix_ind_b)]\n",
    "    rvel = coord_icrs.T.radial_velocity[:, int(pix_ind_l), int(pix_ind_b)]\n",
    "    return CO_profile, rvel\n",
    "profile, rvel = get_CO_profile(165, -7)\n",
    "\n",
    "plt.plot(rvel, profile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateClippedResidual(aspcap, medres, apstar, rv, k = 3):\n",
    "    spectrum = aspcap[1].data\n",
    "    model = aspcap[3].data\n",
    "    err = aspcap[2].data\n",
    "    bitmask = apstar[3].data[0, :]\n",
    "\n",
    "    if medres[1].data is None:\n",
    "        medres_model = np.ones(spectrum.shape)\n",
    "        medres_err =np.zeros(spectrum.shape)\n",
    "    else:\n",
    "        medres_model = np.array(medres[1].data)\n",
    "        medres_err = np.array(medres[3].data)\n",
    "\n",
    "\n",
    "\n",
    "    mask_digits = [0, 1, 2, 9, 12, 13] # 0 BADPIX, 1 CRPIX, 2 SATPIX, 9 PERSIST_HIGH, 12 SIG_SKYLINE, 13 SIG_TELLURIC\n",
    "    mask = np.zeros(bitmask.shape)\n",
    "    for digit in mask_digits:\n",
    "        mask = mask + np.bitwise_and(bitmask.astype(int), 2**digit) \n",
    "\n",
    "    mask = mask.astype(bool)\n",
    "    res_corr = spectrum / model / medres_model\n",
    "    # print('res corr shape', res_corr.shape)\n",
    "    uncertainty_corr = np.sqrt(err**2 + medres_err**2)\n",
    "\n",
    "    sky_residuals = [(15268.1, 1),(15274.1, 1),(15275.9, 1)]\n",
    "    manual_masks = np.zeros(len(wavs))\n",
    "    for sky in sky_residuals:\n",
    "        wl = sky[0]\n",
    "        manual_masks[np.argmin(np.abs(wavs - wl))] = True\n",
    "    manual_masks = manual_masks + np.roll(manual_masks, -1) + np.roll(manual_masks, 1)\n",
    "\n",
    "    # mask_sigmaclip = np.zeros(len(wavs))\n",
    "\n",
    "\n",
    "    maskSigClip, clip_success = sigmaClip(res_corr, uncertainty_corr, k = k)\n",
    "\n",
    "    mask = mask + maskSigClip\n",
    "    mask = mask.astype(bool)\n",
    "\n",
    "    res_corr_ma = np.ma.array(res_corr, mask = mask)\n",
    "    res_corr_filled = res_corr_ma.filled(np.nan)\n",
    "\n",
    "    res_corr_resamp = resample_interp(res_corr_filled, rv)\n",
    "    uncertainty_corr_resamp = resample_interp(uncertainty_corr, rv)\n",
    "\n",
    "    sky_residuals = [(15268.1, 1),(15274.1, 1),(15275.9, 1)]\n",
    "    manual_masks = np.zeros(len(wavs))\n",
    "    for sky in sky_residuals:\n",
    "        wl = sky[0]\n",
    "        manual_masks[np.argmin(np.abs(wavs - wl))] = True\n",
    "    manual_masks = manual_masks + np.roll(manual_masks, -1) + np.roll(manual_masks, 1)\n",
    "\n",
    "\n",
    "    res_corr_resamp = np.ma.array(res_corr_resamp, mask = manual_masks)\n",
    "    res_corr_resamp = res_corr_resamp.filled(np.nan)\n",
    "\n",
    "\n",
    "    return res_corr_resamp, uncertainty_corr_resamp#, clip_success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacefns_v2 import dAV_dd_array\n",
    "from residual_process import reprocess\n",
    "from filehandling import getASPCAP, getapStar\n",
    "\n",
    "class ForegroundModifiedSightline(Sightline):\n",
    "    def __init__(self, stars, coords = None, dAVdd = None, dfore = 400, **kwargs):\n",
    "        # self.all_stars = stars\n",
    "        self.stars = stars[stars['DIST'] > dfore]\n",
    "        dist = self.stars['DIST']\n",
    "\n",
    "        self.make_fgbins()\n",
    "        self.bin_inds = np.digitize(dist, self.bins)\n",
    "\n",
    "        if coords is not None:\n",
    "            self.l, self.b = coords\n",
    "        else:\n",
    "            self.l, self.b = (np.nanmean(self.stars['GLON']), np.nanmean(self.stars['GLAT']))\n",
    "        \n",
    "        self.rvelo = np.zeros(len(self.bins) - 1)\n",
    "        self.get_DIBs(**kwargs)\n",
    "\n",
    "        self.ndim = len(self.voxel_dAVdd)\n",
    "        self.nsig = len(self.stars)\n",
    "\n",
    "        self.test_init_signals = self.model_signals_fg(self.rvelo, self.dAVdd)\n",
    "    \n",
    "    def get_DIBs(self, MADGICS = False, alternative_data_processing = None, **kwargs):\n",
    "        signals = np.zeros((len(self.stars), len(wavs_window)))\n",
    "        signal_errs = np.zeros((len(self.stars), len(wavs_window)))\n",
    "        dAVdd = np.zeros((len(self.stars), len(self.bins)-1))\n",
    "        dAVdd_all = np.zeros((len(self.stars), len(self.bins)-1))\n",
    "        dAVdd_mask =np.zeros((len(self.stars), len(self.bins)-1)).astype(bool)\n",
    "\n",
    "        if alternative_data_processing is not None:\n",
    "            # needs to take aspcap, medres, apstar, rv as arguments\n",
    "            for i in range(len(self.stars)):\n",
    "                star = self.stars[i]\n",
    "                star_rv = star['VHELIO_AVG']\n",
    "                aspcap = fits.open(getASPCAP(star))\n",
    "                apstar = fits.open(getapStar(aspcap))\n",
    "                medres = fits.open(get_medres(star['TEFF'], star['LOGG'], star['M_H']))\n",
    "                sig, err = alternative_data_processing(aspcap, medres, apstar, star_rv)\n",
    "                signals[i, :], signal_errs[i, :] = sig[window], err[window]\n",
    "\n",
    "               \n",
    "                l, b = star['GLON'], star['GLAT']\n",
    "                dAVdd[i], dAVdd_all[i], dAVdd_mask[i] = dAV_dd_array(l, b, self.bins, star['DIST'], **kwargs)\n",
    "        \n",
    "        else:\n",
    "            if MADGICS:\n",
    "                signals_aspcap = np.zeros((len(self.stars), len(wavs_window)))\n",
    "                signal_errs_aspcap = np.zeros((len(self.stars), len(wavs_window)))\n",
    "\n",
    "            for i in range(len(self.stars)):\n",
    "                star = self.stars[i]\n",
    "                star_rv = star['VHELIO_AVG']\n",
    "                res_hdul = fits.open(get_ca_res(star['FILE']))\n",
    "                signals[i, :] = res_hdul[1].data[window]\n",
    "                signal_errs[i, :] = res_hdul[2].data[window]\n",
    "                reprocess_uncertainty = True\n",
    "                if reprocess_uncertainty:\n",
    "                    signal_errs[i, :] = self.reprocess_errs(res_hdul, star['VHELIO_AVG'])[window]\n",
    "                reprocess_residual = True\n",
    "                if reprocess_residual:\n",
    "                    res_repr, err_repr = reprocess(res_hdul, star['VHELIO_AVG'])\n",
    "                    signals[i, :] = res_repr[window]\n",
    "                    signal_errs[i, :] = err_repr[window]\n",
    "                l, b = star['GLON'], star['GLAT']\n",
    "                dAVdd[i], dAVdd_all[i], dAVdd_mask[i] = dAV_dd_array(l, b, self.bins, star['DIST'], **kwargs)\n",
    "\n",
    "                if MADGICS:\n",
    "                    signals_aspcap[i, :] = np.copy(signals[i, :])\n",
    "                    signal_errs_aspcap[i, :] = np.copy(signal_errs[i, :])\n",
    "                    res_hdul_m = fits.open(get_madgics_res(star['FILE']))\n",
    "                    signals[i, :] = res_hdul_m[1].data[0, 125:][window]\n",
    "\n",
    "\n",
    "\n",
    "        self.signals = signals\n",
    "        self.signal_errs = signal_errs\n",
    "        self.dAVdd = dAVdd\n",
    "        self.voxel_dAVdd = np.nanmedian(dAVdd_all, axis = 0)\n",
    "        self.voxel_dAVdd_std = np.nanstd(dAVdd_all, axis = 0, ddof = 1)\n",
    "        self.dAVdd_mask = dAVdd_mask.astype(bool)\n",
    "        # self.dAVdd_v = dAVdd_v\n",
    "        if MADGICS:\n",
    "            self.signals_aspcap = signals_aspcap\n",
    "            self.signal_errs_aspcap = signal_errs_aspcap\n",
    "\n",
    "    def make_fgbins(self, binsep = 10, dfore = 400, **kwargs):\n",
    "        dmin = 0 # start bins at 0pc\n",
    "        dist = self.stars['DIST']\n",
    "        bins = np.sort(np.insert(np.delete(dist, np.where(dist <= dmin)[0]), [0,1], [dmin, dfore]))\n",
    "        # print('BINS BEFORE THING', bins)\n",
    "        i = 0\n",
    "        while i >= 0:\n",
    "            try:\n",
    "                next_bin = np.min(bins[bins > bins[i]])\n",
    "            except:\n",
    "                print('broke:')\n",
    "                print(bins[bins > bins[i]])\n",
    "                print(len(self.stars))\n",
    "\n",
    "            bins[i+1] = np.max([next_bin, bins[i] + binsep]) + 0.01\n",
    "            if bins[i+1] >= np.max(dist):\n",
    "                bins = bins[:i+2]\n",
    "                i = -np.inf\n",
    "            i = i+1\n",
    "        \n",
    "        self.bins = bins\n",
    "\n",
    "    def model_signals_fg(self, rvelo, dAVdd=None, binsep = None):\n",
    "        if dAVdd is None:\n",
    "            dAVdd = self.dAVdd\n",
    "        if binsep is None:\n",
    "            binsep = self.bins[1:]-self.bins[:-1]\n",
    "        signals = np.zeros((len(self.stars), len(wavs_window)))\n",
    "        peak_wavelength = dopplershift(rvelo)\n",
    "        wavs_grid = np.tile(wavs_window, (len(self.bins)-1, 1))\n",
    "        voxel_DIB_unscaled = np.exp(-(wavs_grid - peak_wavelength[:, np.newaxis])**2 / (2 * sigma0**2))\n",
    "        amp = differentialAmplitude(dAVdd, binsep)\n",
    "\n",
    "        def single_signal(amp, bindex):\n",
    "            amp[bindex :] = 0 # THIS MIGHT NEED TO BE -1\n",
    "\n",
    "            voxel_DIB_scaled = -voxel_DIB_unscaled *  amp[:, np.newaxis] \n",
    "            summed_DIB = np.sum(voxel_DIB_scaled, axis = 0)\n",
    "            # continuum = lambda x, m, b : m * (x - lambda0) + b\n",
    "            # cont = continuum(wavs_window, 0, b)\n",
    "            return summed_DIB  + 1\n",
    "\n",
    "\n",
    "        for i in range(len(self.stars)):\n",
    "            star = self.stars[i]\n",
    "            dAVdd_star = dAVdd[i, :]\n",
    "            # amp = Differential_Amplitude(dAVdd_star, self.bins[1:]-self.bins[:-1])\n",
    "            amp = differentialAmplitude(dAVdd_star, 1)\n",
    "\n",
    "            bin_index = self.bin_inds[i]\n",
    "            # signals[i, :] = single_signal(bin_index)\n",
    "            signals[i, :] = single_signal(amp, bin_index)\n",
    "        return signals\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sightlines = []\n",
    "for i in range(len(selected_inds)):\n",
    "    sightlines.append(ForegroundModifiedSightline(CA_meta[selected_inds[i]], dustdata = dust_data, alternative_data_processing = generateClippedResidual))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sightlines = sightlines[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from MCMCfns import logprob_fg, Logprior_Foreground\n",
    "\n",
    "# def logprob_2(p, sl, logprior = logprior_v, loglikely = loglikely_2, **kwargs): ## NEW AS OF 05.16LIke.\n",
    "#     ndim = len(sl.voxel_dAVdd)\n",
    "#     v = p[ :ndim]\n",
    "#     av = p[ndim:].reshape(-1, ndim)\n",
    "#     lp = logprior(v, **kwargs)\n",
    "#     lp_davdd = logprior_davdd(av, AV_base = sl.dAVdd)\n",
    "#     lp_davdd_reg = 0.0 # logprior_davdd_reg(av, sl, **kwargs)\n",
    "#     lp_davdd_reg_group = 0.0. logprior_davdd_reg_group(av, sl)\n",
    "#     if (not np.isfinite(lp)) | (not np.isfinite(lp_davdd)) | (not np.isfinite(lp_davdd_reg)):\n",
    "#         return -np.inf\n",
    "#     return lp + lp_davdd  + lp_davdd_reg + loglikely_2(v, av, sl = sl, **kwargs) + lp_davdd_reg_group # group term added 10.13\n",
    "\n",
    "\n",
    "# def logprob_fg(p, sl, lp_fore = None, **kwargs):\n",
    "#     ndim = len(sl.voxel_dAVdd)\n",
    "    \n",
    "#     lprob = logprob_2(p, sl, **kwargs)\n",
    "#     v = p[ :ndim]\n",
    "#     av = p[ndim:].reshape(-1, ndim) #what shape is dAVddd? \n",
    "\n",
    "#     ### Added 05.08 ###\n",
    "#     lprior_av_min = logprior_davdd_min(av)\n",
    "#     lprob = lprob + lprior_av_min\n",
    "\n",
    "#     lp_fore_v = lp_fore.logprior_foreground_v(v, sl.bins[1:])\n",
    "#     # lp_fore_av = lp_fore.logprior_foreground_av(av, sl.bins[1:])\n",
    "#     return lprob + lp_fore_v #+ lp_fore_av\n",
    "\n",
    "\n",
    "def MCMC_fg(sl, steps = 1000, nwalkers = 100, pool = None, filename = None):\n",
    "    ndim = len(sl.voxel_dAVdd) \n",
    "    nstar = len(sl.stars)\n",
    "    ndim_amp = int(ndim + ndim * nstar)\n",
    "\n",
    "    lp_foreground = Logprior_Foreground(sl.l, sl.b)\n",
    "\n",
    "    \n",
    "    if filename is not None:\n",
    "        backend = emcee.backends.HDFBackend(filename)\n",
    "        backend.reset(nwalkers, ndim_amp)\n",
    "    else:\n",
    "        backend = None\n",
    "    # dAVdd_prior = sl.dAVdd[:]\n",
    "    # dAVdd_prior[dAVdd_prior == 0] = np.nan \n",
    "    # dAVdd_prior_med = np.nanmedian(dAVdd_prior, axis = 1)\n",
    "    # dAVdd_prior_std = np.nanstd(dAVdd_prior, axis = 1, ddof = 1)\n",
    "    # gaussparams = (dAVdd_prior_med, dAVdd_prior_std)\n",
    "    # print(gaussparams)\n",
    "\n",
    "    # with Pool(15) as pool:\n",
    "\n",
    "    sampler = emcee.EnsembleSampler(nwalkers, ndim_amp , logprob_fg, \n",
    "                                    kwargs={'sl': sl, 'lp_fore': lp_foreground}, pool = pool, backend = backend) # OKAY SO I FORGOT TO CHANGE THIS, WAS LOGPROB_2\n",
    "    # init = 12.5 *(np.random.random((nwalkers, ndim_amp)) - 0.5)\n",
    "    init = 10 *  (np.random.random((nwalkers, ndim_amp)) - 0.5)\n",
    "\n",
    "    init[:, ndim:] = np.abs(sl.dAVdd.ravel()[np.newaxis, :] + 0.1*(np.random.random(init[:, ndim:].shape)-0.5))\n",
    "    init[:, ndim:][(init[:, ndim:] <= 0.1)] = 0.11 + 0.05 * np.random.random(np.sum(init[:, ndim:]<= 0.1))\n",
    "    init[:, ndim:] \n",
    "    print('NDIM:', ndim, 'NSTAR:', nstar, 'INITSHAPE:', init.shape)\n",
    "    \n",
    "    sampler.run_mcmc(init,  steps, progress = True, );\n",
    "    \n",
    "    return sampler, ndim, ndim_amp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sl = sightlines[0]\n",
    "ndim = len(sl.voxel_dAVdd) \n",
    "nstar = len(sl.stars)\n",
    "ndim_amp = int(ndim + ndim * nstar)\n",
    "lp_foreground = Logprior_Foreground(sl.l, sl.b)\n",
    "# lp_foreground.logprior_foreground_v(10, 400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = 10 *  (np.random.random((500, ndim_amp)) - 0.5)\n",
    "init[:, ndim:] = np.abs(sl.dAVdd.ravel()[np.newaxis, :] + 0.1*(np.random.random(init[:, ndim:].shape)-0.5))\n",
    "init[:, ndim:][(init[:, ndim:] <= 0.1)] = 0.11 + 0.05 * np.random.random(np.sum(init[:, ndim:]<= 0.1))\n",
    "print(logprob_fg(init[5, :], sl, lp_fore = lp_foreground,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sl.bins[1:].shape\n",
    "sl.dAVdd.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('ndim', sl.ndim)\n",
    "print('nsig', sl.nsig)\n",
    "print('signals shape', sl.signals.shape)\n",
    "print('dA(V)/dd shape', sl.dAVdd.shape)\n",
    "print('dA(V)/dd shape in logprob fn', sl.dAVdd.flatten().reshape(-1, sl.ndim).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sl.dAVdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stp = 1250\n",
    "# sampler, ndim, ndim_amp = MCMC_scary(a, steps = stp, nwalkers = 500)\n",
    "# sTHIsTThisterasdfdsfafsdfsdafampler1, ndim1, ndim_amp1 = MCMC(a1, steps = stp)\n",
    "# sampler2, ndim2, ndim_amp2 = MCMC(a2, steps = stp)\n",
    "# sampler3, ndim3, ndim_amp3 = MCMC(a3, steps = stp)\n",
    "\n",
    "if False:\n",
    "    today = str(datetime.date.today()).split('-')\n",
    "    datelabel = today[1]+today[2]\n",
    "    run_label = 'kt_' + datelabel + 'a'\n",
    "else:\n",
    "    # run_label = 'kt_0513a' # BEST ONE STILL\n",
    "    # run_label = 'kt_0530a'\n",
    "    run_label = 'kt_0513a' # in sigclip_3 \n",
    "    \n",
    "\n",
    "save_individual = False\n",
    "\n",
    "first_run = False\n",
    "\n",
    "\n",
    "\n",
    "if first_run:\n",
    "    if not os.path.exists(os.getcwd() + 'RUNS_H5/240531_SIGCLIP_3/' + run_label):\n",
    "        os.makedirs(os.getcwd() +'RUNS_H5/240531_SIGCLIP_3/' + run_label)\n",
    "        inp = input('Please describe this run:')\n",
    "        with open('RUNS_H5/240531_SIGCLIP_3/global_log.txt', mode = 'a') as global_log:\n",
    "            global_log.write('-------------------------------------------- \\n')\n",
    "            global_log.write(run_label)\n",
    "            global_log.write(inp + '\\n \\n')\n",
    "    with Pool(10) as pool:\n",
    "        for i in range(len(sightlines)):\n",
    "            # try:\n",
    "            if True:\n",
    "                sl_i = sightlines[i]\n",
    "                smplr, ndm, ndm_amp = MCMC_fg(sl_i, steps = stp, nwalkers = 500, pool = pool, filename = 'RUNS_H5/240531_SIGCLIP_3/'+run_label + 'sampler_{}.h5'.format(i))\n",
    "                # smplr_array.append(smplr)\n",
    "                # mid = time.time()\n",
    "                # print('Time mid - start', mid - start) # beat 7:22\n",
    "                # smplr_, ndim_ = MCMC_vonly(sl_i, smplr, steps = 1200, nwalkers = 100, pool = None)\n",
    "                # end = time.time()\n",
    "                # print('Time end - start:',(end - start)/60)\n",
    "                \n",
    "                sl_i.intake(smplr)\n",
    "                state = 'success'\n",
    "            # except Exception as e:\n",
    "            #     print('Something went wrong')\n",
    "            #     sl_i = None \n",
    "            #     state = 'fail'\n",
    "            #     with open('RUNS_FG_SIGCLIP/' + run_label + '/FAILS.txt', mode = 'a') as fails:\n",
    "            #         fails.write(str(e))\n",
    "                \n",
    "            with open('RUNS_H5/240531_SIGCLIP_3/' + run_label + '_LOG.txt', mode = 'a') as log:\n",
    "                logstring = time.asctime() + ' | ' + str(i) + ' | ' + state + '\\n'\n",
    "                log.write(logstring)\n",
    "            \n",
    "            if save_individual == True:\n",
    "                with open('RUNS_FG_SIGCLIP/' + run_label + '/sl_{}.pickle'.format(i), mode = 'wb') as f:\n",
    "                    pickle.dump(sl_i, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = run_label\n",
    "\n",
    "# first_run = False\n",
    "\n",
    "if first_run:\n",
    "    f = open('RUNS_H5/240531_SIGCLIP_3/sightlines_{}.pickle'.format(name),'wb')\n",
    "    pickle.dump(sightlines, f )\n",
    "    f.close()\n",
    "else:\n",
    "    f = open('RUNS_FG_SIGCLIP/' + run_label + '/sightlines_{}.pickle'.format(name), 'rb')\n",
    "\n",
    "    sightlines = pickle.load(f)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SamplerContainer:\n",
    "    def __init__(self, sampler, ndim, ndim_amp):\n",
    "        self.sampler = sampler\n",
    "        self.ndim = ndim\n",
    "        self.ndim_amp = ndim_amp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0517a: 5 sightline run with previous standard priors, etc, likelihood mutiplied by 2\n",
    "# 0517b: 5 sightline run with previous standard priors, etc, likelihood mutiplied by 4\n",
    "# 0517c: should be a normal kt run liike 0513a, first 20 sightlines. This should be my baseline, basically\n",
    "# 0530a: maintains no Gaussian priors on extinction (other than the foreground. 5 sightlines, 1000 steps, 500 walkers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots()\n",
    "# ax.plot(sightlines[0].sampler.chain[:, :, 0].T, color = 'k', alpha = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def polynomial2d( x1, x2, theta = None, uncert = None):  \n",
    "        if theta is None:\n",
    "            theta = np.array([5.03964666, -1.04129592, -0.72842925, -0.20292219,  0.0206567,  -0.14442016])\n",
    "        if uncert is None:\n",
    "            uncert = 2.404363059339516\n",
    "        if np.array(x1).ndim != 1:\n",
    "            x1 = np.array([x1])\n",
    "            x2 = np.array([x2])\n",
    "        x1 = x1 - 160 # FOR CA CLOUD SPECIFICIALLY\n",
    "        x2 = x2 + 8 # DITTO\n",
    "        X = np.array([[np.ones(np.array(x1).shape), x1, x2, x1 * x2, x1**2, x2**2]]).T\n",
    "        matrix = X * theta[:, np.newaxis]\n",
    "        print(matrix.shape)\n",
    "        return np.nansum(matrix, axis = 1).flatten()\n",
    "\n",
    "def box(x, min = -8.5, max = 17.5):\n",
    "     y = np.ones(len(x))\n",
    "     y[x < min] = 0\n",
    "     y[x > max] = 0\n",
    "     return y\n",
    "\n",
    "def prior_for_plot(l, b, x ):\n",
    "    gaussn = lambda x, mu, sig : 1/(np.sqrt(2 * np.pi) * sig) * np.exp(-(x - mu)**2 / (2* sig**2))     \n",
    "    # x = np.linspace(-20, 20, 100)\n",
    "    sig =  2.404363059339516\n",
    "    mu = polynomial2d(l, b)\n",
    "    print(mu)\n",
    "    return gaussn(x, mu, sig) #* box(x)\n",
    "\n",
    "priorx = np.linspace(-20, 20, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_corner(sampler, labels, minval = 50):\n",
    "    dim = sampler.chain.shape[-1]\n",
    "    samples = sampler.chain[:, minval:, :].reshape((-1, dim))\n",
    "    # print(samples)\n",
    "    fig = corner.corner(samples, figsize = (20, 20), labels = labels)\n",
    "    # for ax in fig.axes:\n",
    "        # ax.set_xlim(-15, 15)\n",
    "        # ax.set_ylim(-15, 15) \n",
    "    plt.show()\n",
    "\n",
    "def make_corner_vonly(sampler, ndim, labels, minval = -100):\n",
    "    samples = sampler.chain[:, minval:, :ndim].reshape((-1, ndim))\n",
    "    print(samples.shape)\n",
    "    # print(samples)\n",
    "    fig = corner.corner(samples, figsize = (20, 20), labels = labels)\n",
    "    # for ax in fig.axes:\n",
    "        # ax.set_xlim(-15, 15)\n",
    "        # ax.set_ylim(-15, 15) \n",
    "    return fig\n",
    "    plt.show()\n",
    "\n",
    "if True:\n",
    "    for i in range(0, len(sightlines)):\n",
    "        sl_i = sightlines[i]\n",
    "        ndim = len(sl_i.bins) - 1 \n",
    "        fig = make_corner_vonly(sl_i.sampler, ndim, labels = None, minval =-200)\n",
    "        axes = np.array(fig.axes).reshape(ndim, ndim)\n",
    "        axes[0, 0].plot(priorx, 1e5* prior_for_plot(sl_i.l, sl_i.b, priorx))\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(sightlines)):\n",
    "    sl = sightlines[i]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_signals_fg(rvelo, sl, dAVdd):\n",
    "    # dAVdd = sl.dAVdd\n",
    "    voxeldiffDIB = np.zeros((len(sl.stars), len(wavs_window)))\n",
    "    unsummed_signals = np.zeros((len(sl.stars), len(sl.bins)-1,len(wavs_window)))\n",
    "    # unsummed_signals = np.zeros((len(sl.bins)-1, len(sl.bins)-1,len(wavs_window)))\n",
    "\n",
    "    print(voxeldiffDIB.shape, unsummed_signals.shape, sl.dAVdd.shape)\n",
    "    peak_wavelength = dopplershift(rvelo)\n",
    "    wavs_grid = np.tile(wavs_window, (len(sl.bins) - 1, 1))\n",
    "    voxel_DIB_unscaled = np.exp(-(wavs_grid - peak_wavelength[:, np.newaxis])**2 / (2 * sigma0**2))\n",
    "    amp = differentialAmplitude(dAVdd, sl.bins[1:]-sl.bins[:-1])\n",
    "\n",
    "    def single_signal(amp, bindex):\n",
    "\n",
    "        amp[bindex:] = 0 # THIS MIGHT NEED TO BE -1\n",
    "        # print(amp)\n",
    "\n",
    "        voxel_DIB_scaled = -voxel_DIB_unscaled *  amp[:, np.newaxis] \n",
    "        summed_DIB = np.sum(voxel_DIB_scaled, axis = 0)\n",
    "        # continuum = lambda x, m, b : m * (x - lambda0) + b\n",
    "        # cont = continuum(wavs_window, 0, b)\n",
    "        return summed_DIB  + 1, voxel_DIB_scaled \n",
    "\n",
    "    fgdiffDIB = np.zeros((len(sl.stars), len(wavs_window)))\n",
    "    \n",
    "\n",
    "    for i in range(len(sl.stars)): # Iterate over each star in dAVdd array\n",
    "        print(dAVdd)\n",
    "        dAVdd_bin = dAVdd[i, :] \n",
    "\n",
    "        amp = differentialAmplitude(dAVdd_bin, 1)\n",
    "\n",
    "        bin_index = np.concatenate([sl.bin_inds]).astype(int)[i] # this only goes to \n",
    "        # signals[i, :] = single_signal(bin_index)\n",
    "        voxeldiffDIB[i, :], unsummed_signals[i, :, :] = single_signal(amp, bin_index)\n",
    "        fgdiffDIB[i, :], _ = single_signal(amp, 1)\n",
    "\n",
    "\n",
    "    return voxeldiffDIB, unsummed_signals, fgdiffDIB\n",
    "\n",
    "def plot_DIBS_fg(sampler, sl, plot_objs = None, bestprob = False):\n",
    "    if plot_objs == None:\n",
    "        fig, ax = plt.subplots(figsize = (8, 16))\n",
    "    else:\n",
    "        fig, ax = plot_objs\n",
    "\n",
    "    ndim = len(sl.voxel_dAVdd)\n",
    "    print('ndim', ndim)\n",
    "    nstars = len(sl.stars)\n",
    "    print('nstars', nstars)\n",
    "\n",
    "    samples = sampler.chain[:, :, :].reshape((-1, sampler.chain.shape[-1]))\n",
    "\n",
    "    medians = np.nanmedian(samples[-100:, :], axis = 0)\n",
    "    print('medians shape', medians.shape)\n",
    "\n",
    "    ## NEW THING\n",
    "    if bestprob:\n",
    "        lp = sl.sampler.lnprobability\n",
    "        lp[:, :-100] = -np.infty\n",
    "        w_ind, stp_ind = np.unravel_index(np.argmax(lp), lp.shape)\n",
    "\n",
    "        medians = sl_i.sampler.chain[w_ind, stp_ind, :]\n",
    "\n",
    "    med_velo = medians[:ndim]\n",
    "\n",
    "    med_dAV_dd = medians[ndim:].reshape(-1, ndim)\n",
    "    print(med_dAV_dd)\n",
    "    print('med_velo shape', med_velo.shape)\n",
    "    print('med_dAV_dd shape', med_dAV_dd.shape)\n",
    "    # med_dAV_dd = np.tile(med_dAV_dd, len(sl.stars)).reshape(len(sl.stars), -1)\n",
    "\n",
    "    order_inds = np.array(np.argsort(sl.stars['DIST']))\n",
    "    # order_inds = (np.array(np.argsort(sl.stars['DIST'])))\n",
    "    print('order_inds', order_inds)\n",
    "\n",
    "    signal_recreated, signal_recreated_unsummed, fg_dibs = model_signals_fg(med_velo, sl, med_dAV_dd) \n",
    "\n",
    "    print('signal_recreated.shape', signal_recreated.shape)\n",
    "\n",
    "\n",
    "    ax.plot(wavs[window], fg_dibs[0, :], linestyle = 'dashed', color ='grey')\n",
    "\n",
    "    for i in range(len(order_inds)):\n",
    "        ii = order_inds[i]\n",
    "        print(ii)\n",
    "        offset_i = i+1\n",
    "\n",
    "        # signal_recreated_here = sl.model_signals(med_velo[i], dAVdd = med_dAV_dd[i, :])\n",
    "\n",
    "        ax.plot(wavs_window, sl.signals[ii, :] + 0.05 * offset_i, color = 'C{}'.format(i))\n",
    "        ax.fill_between(wavs_window, sl.signals[ii, :] + sl.signal_errs[ii, :] + 0.05 * offset_i,\n",
    "                         sl.signals[ii, :] - sl.signal_errs[ii, :] + 0.05 * offset_i, color = 'C{}'.format(i), alpha = 0.1)\n",
    "\n",
    "        ax.plot(wavs_window, signal_recreated[ii, :] + 0.05 * offset_i , color = 'C{}'.format(i), linestyle = 'dotted',)# label = 'recreated signal')\n",
    "\n",
    "        for j in range(len(sl.bins)-1):\n",
    "            if j==0:\n",
    "                col = 'grey'\n",
    "            else:\n",
    "                col = 'C{}'.format(j-1)\n",
    "            if j > i+1:\n",
    "                continue\n",
    "            ax.plot(wavs_window, signal_recreated_unsummed[ii, j, : ] + 1  + 0.05 * offset_i, color=col, linestyle = 'dashed', alpha = 1)\n",
    "\n",
    "    # ax.legend(loc = 'lower left', fontsize = 20)\n",
    "\n",
    "    ax.set_xlabel('Wavelength ($\\AA$)', fontsize = 20)\n",
    "    ax.set_ylabel('Normalized Flux', fontsize = 20)\n",
    "    fig.set_facecolor('white')\n",
    "\n",
    "    # ax.set_xticks(np.arange(lambda0-10, lambda0 + 12, 4))\n",
    "    ax.set_xticks(np.linspace(15272-10, 15272 + 10, 5))\n",
    "\n",
    "    # ax.set_yticklabels('')\n",
    "\n",
    "    return signal_recreated, sl.signals, sl.signal_errs\n",
    "\n",
    "chi2s = np.zeros(len(sightlines))\n",
    "sl_lensignals = np.zeros(len(sightlines))\n",
    "\n",
    "recreated_signals = []\n",
    "\n",
    "for i in range(len(sightlines)):\n",
    "    print('N', i)\n",
    "    fig, ax = plt.subplots(figsize = (8, 16))\n",
    "\n",
    "    sl_i = sightlines[i]\n",
    "    sl_lensignals[i] = sl_i.nsig\n",
    "    sampler_i = sl_i.sampler\n",
    "    reproducedDIBs, realDIBs, realDIBerrs = plot_DIBS_fg(sampler_i, sl_i, plot_objs = (fig, ax))\n",
    "\n",
    "    chi2 = np.nansum((realDIBs-reproducedDIBs)**2 / realDIBerrs**2) / np.sum(np.isnan(realDIBs) == False)\n",
    "    chi2s[i] = chi2\n",
    "\n",
    "    # ymin, ymax = ax.get_ylim()\n",
    "    # ax.text(lambda0, ymax - .01, str(chi2))\n",
    "\n",
    "    lp_i = sampler_i.lnprobability\n",
    "    lp_med_i = np.nanmedian(lp_i[:, -100:])\n",
    "    # ax.text(lambda0, ymax - .01, 'sl index {}'.format(i) )\n",
    "    # ax.text(lambda0, ymax - .015, 'lnprob {}'.format(lp_med_i) )\n",
    "\n",
    "    name_i = 'dibs_' + str(i)\n",
    "    # fig.savefig('/uufs/astro.utah.edu/common/home/u1371365/figures/230921_qualfigs/231015_DIBmodels/{}.png'.format(name_i), overwrite = True)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    ### Added 05.13 ###\n",
    "    recreated_signals.append(reproducedDIBs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sl_davdd = np.zeros((len(l_sample.flatten()), dust_data.dustmap.shape[-1]))\n",
    "for i in range(len(l_sample.flatten())): \n",
    "    l_i, b_i = l_sample.flatten()[i], b_sample.flatten()[i]\n",
    "    l_ind, b_ind = find_nearest(l_i, b_i)\n",
    "    sl_davdd[i, :] = np.copy(dust_data.dustmap[b_ind, l_ind, :])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(sightlines)):\n",
    "    sl = sightlines[i]\n",
    "    recreated_signals_i = recreated_signals[i]\n",
    "\n",
    "    chi2_per_signal = np.nansum((sl.signals - recreated_signals_i)**2 / recreated_signals_i, axis = 1)\n",
    "    print(chi2_per_signal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.hist(chi2s)\n",
    "print(chi2s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_velo(sampler, sl , min_walker = None, plot_objs = None, color = None, plot_lines = False, plot_box = False, plot_violin = False, bestprob = False,):\n",
    "    if plot_objs == None:\n",
    "        fig, ax = plt.subplots(figsize = (8,6))\n",
    "    else:\n",
    "        fig, ax = plot_objs\n",
    "    ndim = len(sl.voxel_dAVdd)\n",
    "\n",
    "    walker_max = sampler.chain.shape[1]\n",
    "\n",
    "    if min_walker is None:\n",
    "        min_walker_val = -100\n",
    "    # else:\n",
    "    min_walker_val = walker_max - min_walker\n",
    "\n",
    "    samples = sampler.chain[:, min_walker_val:, :].reshape((-1, sampler.chain.shape[-1]))\n",
    "\n",
    "    vel_samples = samples[:, :sl.ndim]\n",
    "    avg_av = np.nansum(np.median(sl.dAVdd, axis = 0))\n",
    "\n",
    "    medians = np.nanmedian(samples[min_walker_val:, :], axis = 0)\n",
    "    if bestprob:\n",
    "        lp = sl_i.sampler.lnprobability\n",
    "        lp[:, :-100] = -np.infty\n",
    "        w_ind, stp_ind = np.unravel_index(np.argmax(lp), lp.shape)\n",
    "\n",
    "        medians = sl_i.sampler.chain[w_ind, stp_ind, :]\n",
    "\n",
    "    stdevs = np.nanstd(samples[min_walker_val:, :], ddof = 1, axis = 0)\n",
    "\n",
    "    med_velo = medians[:ndim]\n",
    "    std_velo = stdevs[:ndim]\n",
    "\n",
    "\n",
    "    med_dAV_dd = medians[ndim:]\n",
    "    med_dAV_dd = stdevs[ndim:]\n",
    "\n",
    "    perc16, perc50,  perc84 = (np.percentile(samples[min_walker_val:, :], 16, axis = 0), \n",
    "                               np.percentile(samples[min_walker_val:, :], 50, axis = 0),\n",
    "                               np.percentile(samples[min_walker_val:, :], 84, axis = 0) )\n",
    "    velo16, velo50, velo84 = (perc16[:ndim], perc50[:ndim], perc84[:ndim])\n",
    "\n",
    "    # med_dAV_dd = np.tile(med_dAV_dd, len(sl.stars)).reshape(len(sl.stars), -1)\n",
    "\n",
    "\n",
    "    # ax.scatter((a.bins[1:] + a.bins[:-1] ) /2 , med_velo)\n",
    "    # if\n",
    "    # for i in range(len(sl.bins)-1): \n",
    "    #     ax.hlines(med_velo[i], sl.bins[i], sl.bins[i+1], linestyle = 'dashed')\n",
    "    #     if i < len(sl.bins) -2:\n",
    "    #         ax.vlines(sl.bins[i+1], med_velo[i], med_velo[i+1], linestyle = 'dashed')\n",
    "\n",
    "    if color == None:\n",
    "        color_choice = 'k'\n",
    "    else:\n",
    "        color_choice = color\n",
    "    \n",
    "\n",
    "    if plot_box:\n",
    "        # ax.hlines(med_velo, sl.bins[:-1], sl.bins[1:], color = color_choice, linestyle = 'dashed', linewidth = 0.5)\n",
    "        # ax.hlines(velo50, sl.bins[:-1], sl.bins[1:], color = color_choice)\n",
    "        ax.hlines(velo50, sl.bins[:-1], sl.bins[1:], color = 'k')\n",
    "\n",
    "\n",
    "        for j in range(len(sl.bins)-1):\n",
    "            # ax.fill_between([sl.bins[i], sl.bins[i +1]], med_velo[i]+std_velo[i], med_velo[i]-std_velo[i], \n",
    "            #                 alpha = 0.3, color = color_choice, hatch = '/')\n",
    "            ax.fill_between([sl.bins[j], sl.bins[j +1]], velo84[j], velo16[j], \n",
    "                    alpha = 0.3, color = 'C{}'.format(j))\n",
    "\n",
    "    axmin = 350\n",
    "    if plot_violin:\n",
    "        bin_pos = sl.bins[:]\n",
    "        bin_pos[0] = axmin\n",
    "        pos = (bin_pos[1:] + bin_pos[:-1])/2\n",
    "        \n",
    "        w = (bin_pos[1:] - bin_pos[:-1])\n",
    "        ax.violinplot(vel_samples, pos, widths = w, showmeans=False, showextrema=False, showmedians=True,)\n",
    "\n",
    "\n",
    "\n",
    "    # else:  \n",
    "    #     # ax.errorbar((sl.bins[1:] + sl.bins[:-1] ) /2 , med_velo, yerr = std_velo, fmt = '.', color = color_choice, capsize = 5)\n",
    "    #     # ax.scatter((sl.bins[1:] + sl.bins[:-1] ) /2 , med_velo, c = color_choice)\n",
    "    #     ax.errorbar((sl.bins[1:] ) , med_velo, yerr = std_velo, fmt = '.', color = color_choice, capsize = 5)\n",
    "    #     ax.scatter((sl.bins[1:] ) , med_velo, c = color_choice)\n",
    "    #     if plot_lines:\n",
    "    #         ax.hlines(med_velo, sl.bins[:-1], sl.bins[1:], color = color_choice, linestyle = 'solid', linewidth = .5)\n",
    "\n",
    "\n",
    "\n",
    "    # ax.errorbar((sl.bins[1:]),med_velo, xerr = (sl.bins[1:] - sl.bins[:-1], np.zeros(med_velo.shape)), yerr = std_velo, fmt = '.' )\n",
    "    ax.set_xlim(axmin, 600)\n",
    "    ax.set_xlabel('Distance (pc)')\n",
    "    ax.set_ylabel('Radial Velocity (km/s)')\n",
    "\n",
    "    dist_xx = (sl.bins[1:] + sl.bins[:-1] ) /2\n",
    "    # med_velo\n",
    "\n",
    "    return fig, ax, dist_xx, med_velo, std_velo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_plots_sample(samples, sl, logprob = None, chain = None):\n",
    "    v = np.nanmedian(samples[:, :sl.ndim], axis = 0)\n",
    "    davdd = np.nanmedian(samples[:, sl.ndim:], axis = 0).reshape(-1, sl.ndim)\n",
    "    # av_offset = np.nanmedian(samples[:, 2*sl.ndim:], axis = 0)\n",
    "    # davdd_all = np.ones((sl.nsig, sl.ndim)) * davdd + av_offset.reshape((sl.nsig, sl.ndim))\n",
    "\n",
    "    if False: \n",
    "        best_step, best_walker = np.unravel_index(np.argmax(logprob), logprob.shape)\n",
    "        davdd = chain[best_step, best_walker, sl.ndim:2*sl.ndim]\n",
    "        print(davdd.shape)\n",
    "        davdd_all = davdd * np.ones((sl.nsig, sl.ndim)) + av_offset.reshape((sl.nsig, sl.ndim))\n",
    "\n",
    "    def sample_signal():\n",
    "        idx = (np.random.choice(samples.shape[0]))\n",
    "        v = samples[idx, :sl.ndim]\n",
    "        av = samples[idx, sl.ndim:].reshape(-1, sl.ndim)\n",
    "        # av_scatter = samples[idx, 2*sl.ndim:]\n",
    "        # davdd_all = av * np.ones((sl.nsig, sl.ndim)) + av_scatter.reshape((sl.nsig, sl.ndim))\n",
    "        voxeldiffDIB, unsummed_signals, fgdiffDIB  = model_signals_fg(v, sl, av)\n",
    "        return voxeldiffDIB, unsummed_signals, fgdiffDIB\n",
    "\n",
    "    model_signals, signal_recreated_unsummed, fg_unsummed = model_signals_fg(v, sl, davdd)\n",
    "    print( model_signals.shape)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize = (10, 20))\n",
    "\n",
    "    samp_signal = np.zeros((50, len(sl.stars), len(wavs_window)))\n",
    "    samp_unsummed = np.zeros((50, len(sl.stars), len(sl.bins)-1, len(wavs_window)))\n",
    "    samp_fgdiffDIB = np.zeros((50, len(sl.stars), len(wavs_window)))\n",
    "\n",
    "    for idx in range(50):\n",
    "        voxeldiffDIB, unsummed_signals, fgdiffDIB = sample_signal()\n",
    "        samp_signal[idx, :, :] = voxeldiffDIB\n",
    "        samp_unsummed[idx, :, :] = unsummed_signals\n",
    "        samp_fgdiffDIB[idx, : :] = fgdiffDIB\n",
    "\n",
    "    order_inds = np.array(np.argsort(sl.stars['DIST']))\n",
    "    # signal_recreated, signal_recreated_unsummed = model_signals_thing(med_velo, sl, med_dAV_dd) \n",
    "    for i in range(len(order_inds)):\n",
    "        ii = order_inds[i]\n",
    "        # bindex = sl.bin_inds[ii]\n",
    "        # ax.plot(wavs_window, sl.signals[ii, :] + 0.05 * i, color = 'C{}'.format(i))\n",
    "        # ax.fill_between(wavs_window, sl.signals[ii, :] + sl.signal_errs[ii, :] + 0.05 * i,\n",
    "        #                  sl.signals[ii, :] - sl.signal_errs[ii, :] + 0.05 * i, color = 'C{}'.format(bindex), alpha = 0.1)\n",
    "\n",
    "\n",
    "        ax.plot(wavs[window], model_signals[ii, :] + 0.1 * i, color = 'C{}'.format(i))        \n",
    "        ax.plot(wavs[window], sl.signals[ii, :]+ 0.1 * i, color = 'C{}'.format(i))\n",
    "        for k in range(50):\n",
    "            # samp, _, _ = sample_signal()\n",
    "            ax.plot(wavs[window], samp_signal[k, ii, :] + 0.1 * i, color = 'C{}'.format(i), alpha = 0.05)\n",
    "        for j in range(len(sl.bins)-1):\n",
    "            if j==0:\n",
    "                col = 'grey'\n",
    "            else:\n",
    "                col = 'C{}'.format(j-1)\n",
    "            if j > i+1:\n",
    "                continue\n",
    "            ax.plot(wavs_window, unsummed_signals[ii, j, : ] + 1  + 0.1 * i, color=col, linestyle = 'dashed', alpha = 1)\n",
    "        \n",
    "\n",
    "\n",
    "        ax.set_xlabel('Wavelength ($\\AA$)')\n",
    "        ax.set_ylabel('Flux + Offset')\n",
    "        ax.plot(wavs[window], fg_unsummed[0, :]  -0.1, linestyle = 'dashed', color ='grey',)\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "for i in range(len(sightlines)):\n",
    "    print(i)\n",
    "    samples = sightlines[i].sampler.chain.swapaxes(0,1)[-100:, :, :].reshape(-1, sightlines[i].sampler.chain.shape[-1])\n",
    "    print(samples.shape)\n",
    "\n",
    "    make_plots_sample(samples, sightlines[i])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avs = np.zeros(len(sightlines))\n",
    "for i in range(len(sightlines)):\n",
    "    sl_i = sightlines[i]\n",
    "    avs[i] = np.sum(sl_i.voxel_dAVdd)\n",
    "\n",
    "line = lambda x, m, b : m * x + b\n",
    "\n",
    "cnorm = matplotlib.colors.Normalize(np.min(avs), np.max(avs))\n",
    "cmap = plt.get_cmap('viridis')\n",
    "mappable = matplotlib.cm.ScalarMappable(norm = cnorm,  cmap = cmap)\n",
    "\n",
    "\n",
    "sightlines_slopes = np.zeros(len(sightlines))\n",
    "sightlines_slopes_err = np.zeros(len(sightlines))\n",
    "\n",
    "\n",
    "dist_xx_sl = np.array([])\n",
    "velo_yy_sl = np.array([])\n",
    "std_velo_sl = np.array([])\n",
    "\n",
    "priorx = np.linspace(-20, 20, 100)\n",
    "\n",
    "# for i in range(len(sightlines)): \n",
    "for i in range(0, len(sightlines)): \n",
    "\n",
    "    print('N ', i)\n",
    "    fig, axs = plt.subplots(nrows = 2, ncols = 1, figsize = (8,7), sharex = True, gridspec_kw={'height_ratios': [6,1], 'hspace': 0})\n",
    "\n",
    "    \n",
    "\n",
    "    dist_xx = np.array([])\n",
    "    velo_yy = np.array([])\n",
    "    std_velo = np.array([])\n",
    "    sl_i = sightlines[i]\n",
    "    sampler_i = sl_i.sampler\n",
    "    color = cmap(cnorm(avs[i]))\n",
    "    color = 'C'+str(i)\n",
    "    _, __, dist_xx_i, velo_yy_i, std_velo_i = plot_velo(sampler_i, sl = sl_i, min_walker = 10, plot_objs = (fig, axs[0]), color = color, \n",
    "                                                        plot_box = False, plot_violin=True, bestprob = True)\n",
    "    dist_xx = np.concatenate([dist_xx, dist_xx_i])\n",
    "    velo_yy = np.concatenate([velo_yy, velo_yy_i])\n",
    "    std_velo = np.concatenate([std_velo, std_velo_i])\n",
    "\n",
    "    print(dist_xx)\n",
    "    print(velo_yy)\n",
    "\n",
    "\n",
    "\n",
    "    dist_sort = np.argsort(dist_xx)\n",
    "    # print(dist_sort)\n",
    "\n",
    "    try:\n",
    "        filt = (dist_xx[dist_sort] > 400) & (dist_xx[dist_sort] <= 800)\n",
    "        print(dist_xx[dist_sort][filt])\n",
    "        fit_result = curve_fit(line, dist_xx[dist_sort][filt], velo_yy[dist_sort][filt], sigma = std_velo[dist_sort][filt])\n",
    "        print(fit_result)\n",
    "        fit_params = fit_result[0]\n",
    "        fit_result_err = np.sqrt(np.diag(fit_result[1]))\n",
    "        xx_plot = np.linspace(380, 600)\n",
    "\n",
    "        # axs[0].plot(xx_plot, line(xx_plot, fit_params[0], fit_params[1]), label = 'SL ' + str(i))\n",
    "        sightlines_slopes[i] = fit_params[0] \n",
    "        sightlines_slopes_err[i] = fit_result_err[0]\n",
    "    except Exception as e:\n",
    "        print('didn\\'t fit properly')\n",
    "        print(e)\n",
    "        sightlines_slopes[i] = np.nan\n",
    "\n",
    "    # ### ADDDED 03.28 ###\n",
    "    # fgprior = prior_for_plot(sl_i.l, sl_i.b, priorx)\n",
    "    # axs[0].plot(5e2 * fgprior + 350, priorx, color = 'grey', linestyle = 'dashed')\n",
    "\n",
    "    # ### ADDED 03.31 ###\n",
    "    # profile, rvel = get_CO_profile(sl_i.l, sl_i.b)\n",
    "    # axs[0].plot(600- 5e1*profile, rvel)\n",
    "\n",
    "    axs[1].plot(dust_data.distance, sl_davdd[i, :], color = 'k')\n",
    "    # ax.set_ylim(ymin, ymax)\n",
    "    axs[1].set_xlim(350, 600)\n",
    "    axs[1].set_xlabel('Distance (pc)')\n",
    "    axs[1].set_ylabel(r'$ \\langle \\frac{dA_V}{dd} \\rangle $' + '\\n (mag/pc)')\n",
    "    axs[1].set_ylim(0, 0.05)\n",
    "    fig.set_facecolor('white')\n",
    "\n",
    "    ylim0 = (-10, 20)\n",
    "    axs[0].set_ylim(*ylim0)\n",
    "    axs[0].fill_between((350, 400), (ylim0[1], ylim0[1]), (ylim0[0], ylim0[0]), color = 'grey', alpha = 0.1)\n",
    "\n",
    "    ylim1 = (-0.001, 0.05)\n",
    "    axs[1].set_ylim(*ylim1)\n",
    "    axs[1].fill_between((350, 400), (ylim1[1], ylim1[1]), (ylim1[0], ylim1[0]), color = 'grey', alpha = 0.1)\n",
    "\n",
    "    # for j in range(len(sl_i.stars)):\n",
    "    #     axs[1].scatter(sl_i.stars['DIST'][j], sl_davdd[i, find_nearest_dist(sl_i.stars['DIST'][j])])\n",
    "\n",
    "    # axs[0].legend()\n",
    "    # name_i = 'veldist_' + str(i)\n",
    "    # fig.savefig('/uufs/astro.utah.edu/common/home/u1371365/figures/230921_qualfigs/2301015_veldist/{}.png'.format(name_i), overwrite = True )\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    dist_xx_sl = np.concatenate([dist_xx_sl, dist_xx])\n",
    "    velo_yy_sl = np.concatenate([velo_yy_sl, velo_yy])\n",
    "    std_velo_sl = np.concatenate([std_velo_sl, std_velo])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import spearmanr\n",
    "start = 0\n",
    "stop = None\n",
    "def gradientmetric_deriv(array, dist):    \n",
    "    a, b = np.meshgrid(array, array)\n",
    "    c, d = np.meshgrid(dist, dist)\n",
    "    grad_matrix = np.triu(b - a)\n",
    "    deltadist = np.triu(d - c)\n",
    "    nz = grad_matrix != 0\n",
    "    grad_matrix[nz] = grad_matrix[nz] / deltadist[nz]\n",
    "    shape = grad_matrix.shape[0]\n",
    "    return np.sum(grad_matrix) / (0.5 * shape * (shape - 1))\n",
    "\n",
    "sl_metrics = np.zeros(len(sightlines))\n",
    "sl_spearman = np.zeros((len(sightlines), 2))\n",
    "\n",
    "\n",
    "v_all = np.array([], dtype = float)\n",
    "verr_all = np.array([], dtype = float)\n",
    "d_all = np.array([], dtype = float)\n",
    "l_sightline = np.array([], dtype = float)\n",
    "sl_counts = np.zeros(len(sightlines))\n",
    "median_velo_sightline = np.zeros(len(sightlines))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for i in range(len(sightlines)):\n",
    "    sl_i = sightlines[i]\n",
    "    ndim = len(sl_i.voxel_dAVdd)\n",
    "    walker_max = sl_i.sampler.chain.shape[1]\n",
    "    min_walker_val = walker_max - 100\n",
    "    sampler = sl_i.sampler\n",
    "    samples = sampler.chain[:, min_walker_val:, :].reshape((-1, sampler.chain.shape[-1]))\n",
    "    medians = np.nanmedian(samples[min_walker_val:, :], axis = 0)\n",
    "    stdevs = np.nanstd(samples[min_walker_val:, :], ddof = 1, axis = 0)\n",
    "\n",
    "    med_velo = medians[:ndim]\n",
    "    std_velo = stdevs[:ndim]\n",
    "    bin_dist = sl_i.bins[1:]\n",
    "\n",
    "    select_cloud = bin_dist > 400\n",
    "\n",
    "    median_velo_sightline[i] = np.nanmedian(samples[:, :ndim])\n",
    "\n",
    "    metric = np.sum(gradientmetric_deriv(med_velo[select_cloud], bin_dist[select_cloud]))\n",
    "    sl_metrics[i] = metric\n",
    "\n",
    "    spearman_correlation = spearmanr(bin_dist[select_cloud], med_velo[select_cloud])\n",
    "    sl_spearman[i, 0] = spearman_correlation.correlation\n",
    "    sl_spearman[i, 1] = spearman_correlation.pvalue\n",
    "\n",
    "    v_all = np.concatenate([v_all,med_velo])\n",
    "    verr_all = np.concatenate([verr_all, std_velo]) \n",
    "    d_all = np.concatenate([d_all, bin_dist])\n",
    "\n",
    "    l_sightline = np.concatenate([l_sightline, l_sample[i] * np.ones(len(med_velo))])\n",
    "    sl_counts[i] = len(med_velo)\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (6,6))\n",
    "im = ax.imshow(np.nansum(dust_data.dustmap, axis = 2), origin = 'lower', cmap = 'binary', vmin = 0, vmax = 3, extent = (dust_data.l0-9, dust_data.l0+9, dust_data.b0-9, dust_data.b0+9))\n",
    "# masks = (np.nansum(edenhofer, axis = 2) >= 2.2).astype(float)\n",
    "# masks_3 = (np.nansum(edenhofer, axis = 2) < 1.5).astype(float)\n",
    "# im_mask = ax.imshow(np.nansum(edenhofer, axis = 2), origin = 'lower', cmap = 'Reds', alpha = masks, extent = (l0-9, l0+9, b0-9, b0+9))\n",
    "# im_mask_3 = ax.imshow(np.nansum(edenhofer, axis = 2), origin = 'lower', cmap = 'Purples', alpha = masks_3, extent = (l0-9, l0+9, b0-9, b0+9))\n",
    "points = ax.scatter(l_sample[:len(sightlines)], b_sample[:len(sightlines)], c = sl_spearman[:, 0], s= 100 * (1-sl_spearman[:, 1]), vmin = -0.075, vmax = 0.075, cmap = 'coolwarm')\n",
    "ax.set_xlabel('l (deg)')\n",
    "ax.set_ylabel('b (deg)')\n",
    "xmin, xmax = ax.get_xlim()\n",
    "ax.set_xlim(xmax, xmin)\n",
    "# fig.colorbar(im, label = \"A(V)\")\n",
    "fig.colorbar(points, label = 'Spearman Correlation')\n",
    "plt.show()\n",
    "\n",
    "# sl_spearman.astype(np.float16)\n",
    "# fig, ax = plt.subplots()\n",
    "# fil = np.nansum(crit_filament)\n",
    "# fil_idx = np.sum(sl_counts[:fil]).astype(int)\n",
    "\n",
    "# ax.errorbar(d_all[:], v_all[:], yerr = verr_all[:], fmt = '.', capsize = 4, color = 'grey')\n",
    "\n",
    "# points = ax.scatter(d_all[:], v_all[:], c = l_sightline[:], zorder = 5, )\n",
    "\n",
    "# ax.set_xlim(380, 600)\n",
    "# ax.set_xlabel('Distance (pc)')\n",
    "# ax.set_ylabel('Velocity (km/s)')\n",
    "# fig.colorbar(points, label = 'l (deg)')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.flip(np.argsort((sl_spearman[:, 0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter((1-sl_spearman[:, 1]), sl_spearman[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.scatter(np.arange(len(sightlines)), chi2s)\n",
    "ax.set_ylim(0.2, 0.7)\n",
    "ax.grid('on')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C0_means = np.zeros(len(sightlines))\n",
    "for i in range(len(sightlines)):\n",
    "    sl_i = sightlines[i]\n",
    "    profile, rvel = get_CO_profile(sl_i.l, sl_i.b)\n",
    "    profile_mean = np.nansum(profile * rvel) / np.nansum(profile)\n",
    "    print(profile_mean)\n",
    "    C0_means[i] = profile_mean.value\n",
    "\n",
    "samples = sightlines[0].sampler.chain[:, min_walker_val:, :].reshape((-1, sightlines[0].sampler.chain.shape[-1]))\n",
    "samples_v = samples[:, :sightlines[0].ndim]\n",
    "\n",
    "distance_v = np.ones(samples_v.shape) * sightlines[0].bins[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (6,6))\n",
    "im = ax.imshow(np.nansum(dust_data.dustmap, axis = 2), origin = 'lower', cmap = 'binary', vmin = 0, vmax = 3, extent = (dust_data.l0-9, dust_data.l0+9, dust_data.b0-9, dust_data.b0+9))\n",
    "points = ax.scatter(l_sample[:len(sightlines)], b_sample[:len(sightlines)], c = C0_means, cmap = 'viridis',vmin = 0, vmax = 9)\n",
    "ax.set_xlabel('l (deg)')\n",
    "ax.set_ylabel('b (deg)')\n",
    "xmin, xmax = ax.get_xlim()\n",
    "ax.set_xlim(xmax, xmin)\n",
    "# fig.colorbar(im, label = \"A(V)\")\n",
    "fig.colorbar(points, label = 'Mean CO Velocity (km/s)')\n",
    "plt.show()\n",
    "print(np.nanmean(C0_means))\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (6,6))\n",
    "im = ax.imshow(np.nansum(dust_data.dustmap, axis = 2), origin = 'lower', cmap = 'binary', vmin = 0, vmax = 3, extent = (dust_data.l0-9, dust_data.l0+9, dust_data.b0-9, dust_data.b0+9))\n",
    "points = ax.scatter(l_sample[:len(sightlines)], b_sample[:len(sightlines)], c = median_velo_sightline, cmap = 'viridis', vmin = 0, vmax = 9)\n",
    "ax.set_xlabel('l (deg)')\n",
    "ax.set_ylabel('b (deg)')\n",
    "xmin, xmax = ax.get_xlim()\n",
    "ax.set_xlim(xmax, xmin)\n",
    "# fig.colorbar(im, label = \"A(V)\")\n",
    "fig.colorbar(points, label = 'Median DIB Velocity (km/s)')\n",
    "plt.show()\n",
    "np.nanmean(median_velo_sightline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chi2_per_star = []\n",
    "chi2_all = []\n",
    "for i in range(len(sightlines)):\n",
    "    sl = sightlines[i]\n",
    "    recreated_signals_i = recreated_signals[i]\n",
    "\n",
    "\n",
    "     #= np.nansum((realDIBs-reproducedDIBs)**2 / realDIBerrs**2) / np.sum(np.isnan(realDIBs) == False)\n",
    "    # chi2_per_signal = np.nansum((sl.signals - recreated_signals_i)**2 / np.sum(np.isnan(sl.signals)==False, axis = 1)[:, np.newaxis], axis = 1)\n",
    "    chi2_per_signal = np.nansum((sl.signals - recreated_signals_i)**2 / (sl.signal_errs**2) , axis = 1)/ np.sum(np.isnan(sl.signals)==False, axis = 1)[:, np.newaxis]\n",
    "\n",
    "    chi2_per_star.append(chi2_per_signal)\n",
    "\n",
    "    chi2_all.append(np.sum(chi2_per_signal))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chi2_per_star = []\n",
    "chi2_all = np.zeros(len(sightlines))\n",
    "for i in range(len(sightlines)):\n",
    "    sl = sightlines[i]\n",
    "    recreated_signals_i = recreated_signals[i]\n",
    "\n",
    "\n",
    "     #= np.nansum((realDIBs-reproducedDIBs)**2 / realDIBerrs**2) / np.sum(np.isnan(realDIBs) == False)\n",
    "    # chi2_per_signal = np.nansum((sl.signals - recreated_signals_i)**2 / np.sum(np.isnan(sl.signals)==False, axis = 1)[:, np.newaxis], axis = 1)\n",
    "    chi2_per_signal = np.nansum((sl.signals - recreated_signals_i)**2 / (sl.signal_errs**2) , axis = 1) / np.sum(np.isnan(sl.signals)==False, axis = 1)\n",
    "\n",
    "    chi2_per_star.append(chi2_per_signal)\n",
    "    chi2_all[i] = np.nansum((sl.signals - recreated_signals_i)**2 / (sl.signal_errs**2) ) / np.sum(np.isnan(sl.signals)==False,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(np.isnan(sl.signals)==False, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "# ax.scatter(np.arange(len(sightlines)), chi2s, color = 'k')\n",
    "for i in range(len(sightlines)):\n",
    "    per_star_chi2s = chi2_per_star[i]\n",
    "    c = ['C{}'.format(i) for i in range(len(per_star_chi2s))]\n",
    "    ax.scatter(np.ones(len(per_star_chi2s)) * i, per_star_chi2s, c = c)\n",
    "# ax.set_ylim(0.2, 0.7)\n",
    "ax.scatter(np.arange(len(sightlines)), chi2_all, color = 'k', label = 'FG mod + sigma clip')\n",
    "ax.grid('on')\n",
    "\n",
    "ax.set_ylabel('$\\chi^2$')\n",
    "ax.set_xlabel('Sightline Index')\n",
    "fig.set_facecolor('white')\n",
    "ax.legend()\n",
    "# plt.savefig('fg_sigmaclip.png')\n",
    "ax.plot((0, 20), (1.7, 1.7))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argsort(chi2_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'hi''\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (6,6))\n",
    "im = ax.imshow(np.nansum(dust_data.dustmap, axis = 2), origin = 'lower', cmap = 'binary', vmin = 0, vmax = 3, extent = (dust_data.l0-9, dust_data.l0+9, dust_data.b0-9, dust_data.b0+9))\n",
    "\n",
    "points = ax.scatter(l_sample[:len(sightlines)], b_sample[:len(sightlines)], c = sl_spearman[:, 0], s= 100 * (1-chi2_all)**2, vmin = -0.075, vmax = 0.075, cmap = 'coolwarm')\n",
    "ax.set_xlabel('l (deg)')\n",
    "ax.set_ylabel('b (deg)')\n",
    "xmin, xmax = ax.get_xlim()\n",
    "ax.set_xlim(xmax, xmin)\n",
    "# fig.colorbar(im, label = \"A(V)\")\n",
    "fig.colorbar(points, label = 'Spearman Correlation')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
