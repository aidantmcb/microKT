{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/uufs/astro.utah.edu/common/home/u1371365/.local/lib/python3.10/site-packages/matplotlib/projections/__init__.py:63: UserWarning: Unable to import Axes3D. This may be due to multiple versions of Matplotlib being installed (e.g. as a system package and as a pip package). As a result, the 3D projection is not available.\n",
      "  warnings.warn(\"Unable to import Axes3D. This may be due to multiple versions of \"\n"
     ]
    }
   ],
   "source": [
    "from multiprocessing import Pool\n",
    "import multiprocessing as mp\n",
    "import os\n",
    "os.environ['OMP_NUM_THREADS'] = \"1\"\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import astropy.units as u  \n",
    "import astropy.constants as c\n",
    "from astropy.coordinates import SkyCoord\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import Normalize\n",
    "import matplotlib \n",
    "\n",
    "from astropy.io import fits\n",
    "from astropy.table import Table, join\n",
    "from astropy.wcs import WCS\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "from dustmaps.vergely2022 import Vergely2022Query\n",
    "from dustmaps.edenhofer2023 import Edenhofer2023Query\n",
    "\n",
    "import pickle \n",
    "import sys\n",
    "import os\n",
    "import tqdm\n",
    "import datetime\n",
    "\n",
    "import emcee\n",
    "import corner\n",
    "\n",
    "import h5py\n",
    "import multiprocessing as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import globalvars\n",
    "dust_data = globalvars.DustData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2545987/2315330892.py:4: DeprecationWarning: `product` is deprecated as of NumPy 1.25.0, and will be removed in NumPy 2.0. Please use `prod` instead.\n",
      "  edenhofer = np.array(f['data'])\n"
     ]
    }
   ],
   "source": [
    "map_fname = '/uufs/astro.utah.edu/common/home/u1371365/DIB_KT_CACloud/edenhofer_out.h5'\n",
    "\n",
    "with h5py.File(map_fname, 'r') as f:\n",
    "    edenhofer = np.array(f['data'])\n",
    "    dust_data.intake_map(edenhofer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from specfns import get_wavs, resample_interp, dopplershift, lambda0, sigma0\n",
    "from filehandling import get_ca_res, get_madgics_res, get_medres\n",
    "from spacefns_v2 import select_stars, find_nearest, find_radius, differentialAmplitude\n",
    "from MCMCfns import logprob_2\n",
    "from sightline import Sightline\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/uufs/chpc.utah.edu/common/home/sdss/dr17/env/APOGEE_STARHORSE/APOGEE_DR17_EDR3_STARHORSE_v2.fits'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2545987/911313378.py\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mCAMADGICSresdir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/uufs/astro.utah.edu/common/home/u1371365/Data/230829_MADGICSResiduals/'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mstarhorsepath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/uufs/chpc.utah.edu/common/home/sdss/dr17/env/APOGEE_STARHORSE/APOGEE_DR17_EDR3_STARHORSE_v2.fits'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mstarhorse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstarhorsepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhdu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mstarhorse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstarhorse\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'APOGEE_ID'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'dist16'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'dist50'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'dist84'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'AV16'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'AV50'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'AV84'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/astropy/table/connect.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0mdescriptions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"descriptions\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregistry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;31m# For some readers (e.g., ascii.ecsv), the returned `out` class is not\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/astropy/io/registry/core.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, cls, format, cache, *args, **kwargs)\u001b[0m\n\u001b[1;32m    198\u001b[0m                                 \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcache\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m                             )\n\u001b[0;32m--> 200\u001b[0;31m                             \u001b[0mfileobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m                         \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m                             \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/uufs/chpc.utah.edu/sys/installdir/r8/python/3.10.3/lib/python3.10/contextlib.py\u001b[0m in \u001b[0;36m__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    133\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"generator didn't yield\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/astropy/utils/data.py\u001b[0m in \u001b[0;36mget_readable_fileobj\u001b[0;34m(name_or_obj, encoding, cache, show_progress, remote_timeout, sources, http_headers, use_fsspec, fsspec_kwargs, close_files)\u001b[0m\n\u001b[1;32m    362\u001b[0m                     \u001b[0mhttp_headers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhttp_headers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m                 )\n\u001b[0;32m--> 364\u001b[0;31m             \u001b[0mfileobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFileIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_obj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    365\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_url\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m                 \u001b[0mdelete_fds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfileobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/uufs/chpc.utah.edu/common/home/sdss/dr17/env/APOGEE_STARHORSE/APOGEE_DR17_EDR3_STARHORSE_v2.fits'"
     ]
    }
   ],
   "source": [
    "CA_meta = Table(fits.open('../Data/230420_CAResiduals/CA_meta.fits')[1].data)\n",
    "CAresdir = '/uufs/astro.utah.edu/common/home/u1371365/Data/230420_CAResiduals/'\n",
    "CAMADGICSresdir = '/uufs/astro.utah.edu/common/home/u1371365/Data/230829_MADGICSResiduals/'\n",
    "# starhorsepath = '/uufs/chpc.utah.edu/common/home/sdss/dr17/env/APOGEE_STARHORSE/APOGEE_DR17_EDR3_STARHORSE_v2.fits'\n",
    "# starhorse = Table.read(starhorsepath, hdu = 1)\n",
    "# starhorse = starhorse['APOGEE_ID', 'dist16', 'dist50', 'dist84', 'AV16', 'AV50', 'AV84']\n",
    "\n",
    "CA_meta = join(CA_meta, starhorse, keys = 'APOGEE_ID', join_type = 'left')\n",
    "\n",
    "CA_meta_full = CA_meta.copy()\n",
    "\n",
    "with open('/uufs/astro.utah.edu/common/home/u1371365/DIB_KT_CACloud/goodbad.pickle', mode = 'rb') as f:\n",
    "    goodbad = pickle.load(f)\n",
    "\n",
    "# added 02.01\n",
    "data_criteria = (((CA_meta['SNR'] > 80) & (CA_meta['TEFF'] > 5000)) | (CA_meta['SNR'] > 150)) & (CA_meta['ASPCAP_CHI2_1'] > 1) & (CA_meta['ASPCAP_CHI2_1'] < 5)\n",
    "print(np.sum(data_criteria))\n",
    "CA_meta= CA_meta[data_criteria]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wavs = get_wavs()\n",
    "window = (wavs > lambda0 -10) & (wavs < lambda0 + 10)\n",
    "wavs_window = wavs[window]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91\n",
      "23\n",
      "28\n"
     ]
    }
   ],
   "source": [
    "ds = 2.5 # x downsampled\n",
    "rad = 0.23\n",
    "sample_dim_l = np.linspace(159, 167, int(8 / (ds * rad)))\n",
    "sample_dim_b = np.linspace(-12.5 , -4.5, int(8 / (ds * rad)))\n",
    "sample_grid_l, sample_grid_b = np.meshgrid(sample_dim_l, sample_dim_b)\n",
    "grid_map_inds = np.array([find_nearest(sample_grid_l.flatten()[i], sample_grid_b.flatten()[i]) for i in range(len(sample_grid_l.flatten()))]).T\n",
    "grid_map = np.nansum(np.copy(edenhofer[grid_map_inds[1], grid_map_inds[0], :]).reshape(*sample_grid_l.shape, -1), axis = 2)\n",
    "grid_Nstar = np.array([np.nansum((np.abs((sample_grid_l.flatten()[i] - CA_meta['GLON'])) <= rad) & \n",
    "            (np.abs((sample_grid_b.flatten()[i] - CA_meta['GLAT'])) <= rad)) for i in range(len(sample_grid_l.flatten()))]).reshape(*sample_grid_l.shape)\n",
    "\n",
    "filament_l = (159, 169)\n",
    "filament_b = (-10, -6)\n",
    "\n",
    "N_min = 5\n",
    "radius_min = np.zeros(sample_grid_l.shape)\n",
    "mgrid = np.mgrid[0:len(sample_dim_l), 0:len(sample_dim_b)]\n",
    "for i in mgrid[0].flatten():\n",
    "    for j in mgrid[1].flatten():\n",
    "        radius_min[i, j] = find_radius(sample_grid_l[i, j], sample_grid_b[i, j], N_min, CA_meta)\n",
    "        radius_min[i, j] = np.max([radius_min[i, j], 0.23])\n",
    "\n",
    "radius_max = 0.4\n",
    "print(np.nansum(radius_min < radius_max))\n",
    "\n",
    "\n",
    "crit_filament = ((sample_grid_l > filament_l[0]) & (sample_grid_l < filament_l[1]) & \n",
    "                 (sample_grid_b > filament_b[0]) & (sample_grid_b < filament_b[1]) &\n",
    "                 (grid_map > 2.2) & (radius_min < 0.5)) #(grid_Nstar > 5) & (grid_Nstar <= 10))\n",
    "\n",
    "crit_background =  (((sample_grid_l <= filament_l[0]) | (sample_grid_l >= filament_l[1]) |\n",
    "                 (sample_grid_b <= filament_b[0]) | (sample_grid_b >= filament_b[1])) &\n",
    "                 (grid_map <= 1.5) & (radius_min < radius_max)) #(grid_Nstar > 5) & (grid_Nstar <= 10))\n",
    "\n",
    "# crit_coverage = (np.sum() => 1 & )\n",
    "\n",
    "N_filament = np.sum(crit_filament)\n",
    "N_background = np.sum(crit_background)\n",
    "print(np.sum(crit_filament))\n",
    "print(np.sum(crit_background))\n",
    "l_fil, b_fil, AV_fil = (sample_grid_l[crit_filament].flatten(), sample_grid_b[crit_filament].flatten(),\n",
    "                        grid_map[crit_filament].flatten())\n",
    "l_off, b_off, AV_off = (sample_grid_l[crit_background].flatten(), sample_grid_b[crit_background].flatten(),\n",
    "                        grid_map[crit_background].flatten())\n",
    "\n",
    "l_sample, b_sample, AV_sample = (np.concatenate([l_fil, l_off]), np.concatenate([b_fil, b_off]),\n",
    "                                  np.concatenate([AV_fil, AV_off]))\n",
    "radius_min_fil = radius_min[crit_filament].flatten()\n",
    "radius_min_off = radius_min[crit_background].flatten()\n",
    "radius_sample = np.concatenate([radius_min_fil, radius_min_off])\n",
    "\n",
    "selected_inds = []\n",
    "for i in range(len(l_sample)):\n",
    "    l_center, b_center = l_sample[i], b_sample[i]\n",
    "    rad_i = radius_sample[i]\n",
    "    selection = select_stars(CA_meta, l_center, b_center, radius = rad_i)\n",
    "    # print(len(selection))\n",
    "    selected_inds.append(selection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.4 * 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dibfn = lambda x, mu, sigma, a: 1-a * np.exp(-0.5 * (x - mu)**2 / sigma**2)\n",
    "def sigma_clip_mask(y, x = wavs, k = 2.5):\n",
    "    y_over_gauss = None\n",
    "\n",
    "    try:\n",
    "        gaussfit = curve_fit(dibfn, x[window], y[window].filled(np.nan), p0 = (15272, 1.2, 0.05), bounds = ([15269, 0.5, 0], [15275, 2, 0.15]), check_finite = False, nan_policy = 'omit')\n",
    "\n",
    "    except:\n",
    "        # gaussfit = ((15272, 1.2, 0.05),())\n",
    "        print('fail')\n",
    "        return None, None\n",
    "    #     y_over_gauss = None\n",
    "    #     gaussfit = ((15272, 1.2, 0.05),())\n",
    "    #     # fit = dibfn(x, 15272.42, 1.2, 0.05)\n",
    "    #     # y_over_gauss = y / fit\n",
    "    #     print('POOR GAUSS FIT IN SIGMA CLIP')\n",
    "    y_over_gauss = y / dibfn(x, *gaussfit[0])\n",
    "\n",
    "    med = np.nanmedian(y_over_gauss[window])\n",
    "    stdev = np.std(y_over_gauss[window], ddof = 1)\n",
    "    mask = np.abs(y_over_gauss - med) > k * stdev\n",
    "    mask = mask + np.roll(mask, -1) + np.roll(mask, -1)\n",
    "    mask = mask.astype(bool)\n",
    "    return mask, stdev\n",
    "\n",
    "def sigmaClip(y, yerr,k=2.5):\n",
    "    clip = True\n",
    "    clip_iters = 0\n",
    "    std = np.nanstd(y[window], ddof = 1)\n",
    "    mask = np.zeros(y.shape).astype(bool)\n",
    "    clip_success = True\n",
    "\n",
    "    while clip:\n",
    "        clip_mask, std_clipped = sigma_clip_mask(np.ma.array(y, mask = mask.copy()), k = k)\n",
    "        if clip_mask is None:\n",
    "            clip_success = False\n",
    "            return mask, clip_success\n",
    "        clip_mask = clip_mask.filled(False)\n",
    "\n",
    "        if std - std_clipped  < 1e-4:\n",
    "            clip = False\n",
    "\n",
    "\n",
    "        else:\n",
    "            clip_iters += 1\n",
    "            std = std_clipped\n",
    "            mask = mask + clip_mask\n",
    "\n",
    "    return mask, clip_success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateClippedResidual(aspcap, medres, apstar, rv, k = 2.5):\n",
    "    spectrum = aspcap[1].data\n",
    "    model = aspcap[3].data\n",
    "    err = aspcap[2].data\n",
    "    bitmask = apstar[3].data[0, :]\n",
    "\n",
    "    if medres[1].data is None:\n",
    "        medres_model = np.ones(spectrum.shape)\n",
    "        medres_err =np.zeros(spectrum.shape)\n",
    "    else:\n",
    "        medres_model = np.array(medres[1].data)\n",
    "        medres_err = np.array(medres[3].data)\n",
    "\n",
    "\n",
    "\n",
    "    mask_digits = [0, 1, 2, 9, 12, 13] # 0 BADPIX, 1 CRPIX, 2 SATPIX, 9 PERSIST_HIGH, 12 SIG_SKYLINE, 13 SIG_TELLURIC\n",
    "    mask = np.zeros(bitmask.shape)\n",
    "    for digit in mask_digits:\n",
    "        mask = mask + np.bitwise_and(bitmask.astype(int), 2**digit) \n",
    "\n",
    "    mask = mask.astype(bool)\n",
    "    res_corr = spectrum / model / medres_model\n",
    "    # print('res corr shape', res_corr.shape)\n",
    "    uncertainty_corr = np.sqrt(err**2)# + medres_err**2)\n",
    "\n",
    "    sky_residuals = [(15268.1, 1),(15274.1, 1),(15275.9, 1)]\n",
    "    manual_masks = np.zeros(len(wavs))\n",
    "    for sky in sky_residuals:\n",
    "        wl = sky[0]\n",
    "        manual_masks[np.argmin(np.abs(wavs - wl))] = True\n",
    "    manual_masks = manual_masks + np.roll(manual_masks, -1) + np.roll(manual_masks, 1)\n",
    "\n",
    "    # mask_sigmaclip = np.zeros(len(wavs))\n",
    "\n",
    "\n",
    "    maskSigClip, clip_success = sigmaClip(res_corr, uncertainty_corr, k = k)\n",
    "\n",
    "    mask = mask + maskSigClip\n",
    "    mask = mask.astype(bool)\n",
    "\n",
    "    res_corr_ma = np.ma.array(res_corr, mask = mask)\n",
    "    res_corr_filled = res_corr_ma.filled(np.nan)\n",
    "\n",
    "    res_corr_resamp = resample_interp(res_corr_filled, rv)\n",
    "    uncertainty_corr_resamp = resample_interp(uncertainty_corr, rv)\n",
    "\n",
    "    sky_residuals = [(15268.1, 1),(15274.1, 1),(15275.9, 1)]\n",
    "    manual_masks = np.zeros(len(wavs))\n",
    "    for sky in sky_residuals:\n",
    "        wl = sky[0]\n",
    "        manual_masks[np.argmin(np.abs(wavs - wl))] = True\n",
    "    manual_masks = manual_masks + np.roll(manual_masks, -1) + np.roll(manual_masks, 1)\n",
    "\n",
    "\n",
    "    res_corr_resamp = np.ma.array(res_corr_resamp, mask = manual_masks)\n",
    "    res_corr_resamp = res_corr_resamp.filled(np.nan)\n",
    "\n",
    "\n",
    "    return res_corr_resamp, uncertainty_corr_resamp#, clip_success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/uufs/astro.utah.edu/common/home/u1371365/nanoKT_v1/residual_process.py:7: RuntimeWarning: invalid value encountered in divide\n",
      "  res = hdu_rf[0, :] / hdu_rf[2, :]\n",
      "/uufs/astro.utah.edu/common/home/u1371365/nanoKT_v1/residual_process.py:8: RuntimeWarning: divide by zero encountered in divide\n",
      "  res_corr = res / hdu_rf[4, :]\n"
     ]
    }
   ],
   "source": [
    "sightlines = []\n",
    "for i in range(len(selected_inds)):\n",
    "    sightlines.append(Sightline(CA_meta[selected_inds[i]], dustdata = dust_data)),#) alternative_data_processing = generateClippedResidual))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sightlines = sightlines[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from  bayesianFramework import logprobability\n",
    "\n",
    "def runMCMC(sl, steps = 500, nwalkers = 400, pool = None, filename = None):\n",
    "    ndim = sl.ndim\n",
    "    nstar = sl.nsig\n",
    "    nparams = 2 * ndim + ndim * nstar\n",
    "    \n",
    "    if filename is not None:\n",
    "        backend = emcee.backends.HDFBackend(filename)\n",
    "        backend.reset(nwalkers, nparams)\n",
    "    else:\n",
    "        backend = None\n",
    "\n",
    "    sampler = emcee.EnsembleSampler(nwalkers, nparams , logprobability, \n",
    "                                    kwargs={'sl': sl, 'k': 3}, pool = pool, backend = backend, )\n",
    "    \n",
    "    init = 10 *  (np.random.random((nwalkers, nparams)) - 0.5)\n",
    "    init[:, ndim:2*ndim] = np.abs(sl.voxel_dAVdd.ravel()[np.newaxis, :] + 0.1*(np.random.random(init[:, ndim:2*ndim].shape)-0.5))\n",
    "    init[:, 2*ndim:] = 0.1* (np.random.random(size = init[:, 2*ndim:].shape) - 0.5)\n",
    "    print('NDIM:', ndim, 'NSTAR:', nstar, 'INITSHAPE:', init.shape)\n",
    "    \n",
    "    sampler.run_mcmc(init,  steps, progress = True, skip_initial_state_check=True);\n",
    "    \n",
    "    return sampler, ndim, nparams, init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sl = sightlines[0]\n",
    "if False:\n",
    "    with mp.Pool(10) as pool:\n",
    "        for i in range(len(sightlines)):\n",
    "            sl_i = sightlines[i]\n",
    "            sampler, _, __, init = runMCMC(sl_i, pool = pool, steps = 2000, nwalkers = 200, filename = 'RUNS_H5/240602_reduceuncert/sightline_standard{}.h5'.format(i),)\n",
    "            sl_i.intake(sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from  bayesianFramework import logprobability\n",
    "\n",
    "# logprobability(init, sightlines[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sightlines[0].sampler.chain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Sightline' object has no attribute 'sampler'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2543765/2821713379.py\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# IF LOADING FROM SLS INSTEAD\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# sightlines = sightlines[:]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mchains\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0msl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msampler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mswapaxes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msl\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msightlines\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprobabilities\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0msl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msampler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_log_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msl\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msightlines\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_2543765/2821713379.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# IF LOADING FROM SLS INSTEAD\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# sightlines = sightlines[:]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mchains\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0msl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msampler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mswapaxes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msl\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msightlines\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprobabilities\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0msl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msampler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_log_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msl\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msightlines\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Sightline' object has no attribute 'sampler'"
     ]
    }
   ],
   "source": [
    "# IF LOADING FROM SLS INSTEAD\n",
    "# sightlines = sightlines[:]\n",
    "chains = [sl.sampler.chain.swapaxes(0, 1) for sl in sightlines]\n",
    "probabilities = [sl.sampler.get_log_prob() for sl in sightlines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chains = []\n",
    "probabilities = []\n",
    "for i in range(len(sightlines)):\n",
    "    reader = emcee.backends.HDFBackend('RUNS_H5/240602_reduceuncert/sightline_standard{}.h5'.format(i))\n",
    "    chains.append(reader.get_chain())\n",
    "    probabilities.append(reader.get_log_prob())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(reader.get_chain().shape)\n",
    "# print(sightlines[0].sampler.chain.shape)\n",
    "# print(chains[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reader = emcee.backends.HDFBackend('RUNS_H5/sightline_5000_iters_standard_0.h5')\n",
    "# chain = reader.get_chain()\n",
    "# log_prob_vals = reader.get_log_prob()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logprobability(init[0, :], sl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def logprior_velocity(v):\n",
    "#     if (np.any(v < -8.5)) or (np.any(v > 17.5)):\n",
    "#         return -np.inf\n",
    "#     return 0.0\n",
    "\n",
    "# def logprior_davdd(av):\n",
    "#     if np.any(av < 0):\n",
    "#         return -np.inf\n",
    "#     return 0.0\n",
    "\n",
    "# def logprior_avscatter(av_offset):\n",
    "#     a_std = 0.010189143589820518\n",
    "#     val = -0.5 * np.nansum((av_offset)**2 / (a_std**2))\n",
    "#     return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# v = init[:, :sl.ndim]\n",
    "# print(logprior_velocity(v))\n",
    "# av = init[:, sl.ndim:2*sl.ndim]\n",
    "# print(logprior_davdd(av))\n",
    "# av_offset = init[:, 2*sl.ndim:]\n",
    "# print(logprior_avscatter(av_offset))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# sampler.run_mcmc(init, 5000, progress = True, skip_initial_state_check=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(probabilities[0])\n",
    "ax.set_xlabel('Step')\n",
    "ax.set_ylabel('Log-Probability')\n",
    "plt.show()\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(chains[0][:, :, 0])\n",
    "ax.set_xlabel('Step')\n",
    "ax.set_ylabel('chain')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unravel_index(np.argmax(probabilities[0]), probabilities[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax= plt.subplots()\n",
    "# ax.plot(sampler.chain[:, :, 2].T, color = 'k', alpha = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_corner_vonly(sampler, ndim, labels, chain = None, minval = -100):\n",
    "    if chain is None:\n",
    "        samples = sampler.chain[:, minval:, :ndim].reshape((-1, ndim))\n",
    "    else:\n",
    "        samples = chain[minval:, :, :ndim].reshape((-1, ndim))\n",
    "    print(samples.shape)\n",
    "    # print(samples)\n",
    "    fig = corner.corner(samples, figsize = (20, 20), labels = labels)\n",
    "    # for ax in fig.axes:\n",
    "        # ax.set_xlim(-15, 15)\n",
    "        # ax.set_ylim(-15, 15) \n",
    "    plt.show()\n",
    "def make_corner_avonly(sampler, ndim, labels, chain = None,  minval = -100):\n",
    "    if chain is None:\n",
    "        samples = sampler.chain[:, minval:, ndim:2*ndim].reshape((-1, ndim))\n",
    "    else:\n",
    "        samples = chain[minval:, :, ndim:2*ndim].reshape((-1, ndim))\n",
    "    print(samples.shape)\n",
    "    # print(samples)\n",
    "    fig = corner.corner(samples, figsize = (20, 20), labels = labels)\n",
    "    # for ax in fig.axes:\n",
    "        # ax.set_xlim(-15, 15)\n",
    "        # ax.set_ylim(-15, 15) \n",
    "    plt.show()\n",
    "def make_corner_av_offsetonly(sampler, ndim, nsig, labels, chain = None, minval = -100):\n",
    "\n",
    "    # samples = sampler.chain[:, minval:, 2 * ndim:].reshape((-1, ndim * nsig))\n",
    "    if chain is None:\n",
    "        samples = sampler.chain[:, minval:, 2*ndim:].reshape((-1, ndim))\n",
    "    else:\n",
    "        samples = chain[minval:,:,  2*ndim:].reshape((-1, ndim))\n",
    "    print(samples.shape)\n",
    "    # print(samples)\n",
    "    fig = corner.corner(samples, figsize = (20, 20), labels = labels)\n",
    "    # for ax in fig.axes:\n",
    "        # ax.set_xlim(-15, 15)\n",
    "        # ax.set_ylim(-15, 15) \n",
    "    plt.show()\n",
    "idx = 0\n",
    "make_corner_vonly(None, sightlines[idx].ndim, None, chain = chains[idx])\n",
    "make_corner_avonly(None, sightlines[idx].ndim, None, chain = chains[idx])\n",
    "make_corner_av_offsetonly(None, sightlines[idx].ndim, sl.nsig, None, chain = chains[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# corner.corner(chain[-100:, :, :sightlines[0].ndim].reshape((-1, sightlines[0].ndim)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# samples = sl.sampler.chain[:, int(0.8 * sampler.chain.shape[1]), :]\n",
    "\n",
    "def make_plots(samples, sl, logprob = None, chain = None):\n",
    "    v = np.nanmedian(samples[:, :sl.ndim], axis = 0)\n",
    "    davdd = np.nanmedian(samples[:, sl.ndim:2*sl.ndim], axis = 0)\n",
    "    av_offset = np.nanmedian(samples[:, 2*sl.ndim:], axis = 0)\n",
    "    davdd_all = np.ones((sl.nsig, sl.ndim)) * davdd + av_offset.reshape((sl.nsig, sl.ndim))\n",
    "\n",
    "    if logprob is not None: \n",
    "\n",
    "        best_step, best_walker = np.unravel_index(np.argmax(logprob), logprob.shape)\n",
    "        davdd = chain[best_step, best_walker, sl.ndim:2*sl.ndim]\n",
    "        print(davdd.shape)\n",
    "        davdd_all = davdd * np.ones((sl.nsig, sl.ndim)) + av_offset.reshape((sl.nsig, sl.ndim))\n",
    "\n",
    "\n",
    "    model_signals = sl.model_signals(v, davdd_all)\n",
    "    print( model_signals.shape)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize = (10, 20))\n",
    "\n",
    "    for i in range(len(model_signals)):\n",
    "        j = sl.bin_inds[i] - 1\n",
    "\n",
    "        ax.plot(wavs[window], model_signals[j, :] + 0.1 * j, color = 'C{}'.format(i))        \n",
    "        ax.plot(wavs[window], sl.signals[j, :]+ 0.1 * j, color = 'C{}'.format(i))\n",
    "        print(sl.stars[j]['DIST'])\n",
    "\n",
    "\n",
    "    # fig, ax = plt.subplots()\n",
    "    # ax.hist(v.flatten(), bins = 50, histtype = 'step', color = 'k')\n",
    "    # ax.set_xlabel('Velocity')\n",
    "    # ax.set_ylabel('Frequency')\n",
    "    # fig, ax = plt.subplots()\n",
    "    # ax.hist(davdd.flatten(), bins = 50, histtype = 'step', color = 'k')\n",
    "    # ax.set_xlabel('dAV/dD')\n",
    "    # ax.set_ylabel('Frequency')\n",
    "    # fig, ax = plt.subplots()\n",
    "    # ax.hist(av_offset.flatten(), bins = 50, histtype = 'step', color = 'k')\n",
    "    # ax.set_xlabel('AV Offset')\n",
    "    # ax.set_ylabel('Frequency')\n",
    "    # plt.show()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(len(sightlines)):\n",
    "#     sl_i = sightlines[i]\n",
    "#     chain = chains[i]\n",
    "#     samples = chain[:, int(0.8 * chain.shape[1]), :]\n",
    "#     # samples = sl_i.sampler.chain[:, int(0.8 * sampler.chain.shape[1]), :]\n",
    "\n",
    "#     make_plots(samples, sl_i, logprob = probabilities[i], chain = chains[i])\n",
    "#     plt.show()\n",
    "\n",
    "# samples_noAVpriors = chain[:, int(0.8 * chain.shape[1]), :]\n",
    "# make_plots(samples_noAVpriors, sightlines[0], logprob = log_prob_vals, chain = chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_plots_sample(samples, sl, logprob = None, chain = None):\n",
    "    v = np.nanmedian(samples[:, :sl.ndim], axis = 0)\n",
    "    davdd = np.nanmedian(samples[:, sl.ndim:2*sl.ndim], axis = 0)\n",
    "    av_offset = np.nanmedian(samples[:, 2*sl.ndim:], axis = 0)\n",
    "    davdd_all = np.ones((sl.nsig, sl.ndim)) * davdd + av_offset.reshape((sl.nsig, sl.ndim))\n",
    "\n",
    "    if False: \n",
    "        best_step, best_walker = np.unravel_index(np.argmax(logprob), logprob.shape)\n",
    "        davdd = chain[best_step, best_walker, sl.ndim:2*sl.ndim]\n",
    "        print(davdd.shape)\n",
    "        davdd_all = davdd * np.ones((sl.nsig, sl.ndim)) + av_offset.reshape((sl.nsig, sl.ndim))\n",
    "\n",
    "    def sample_signal():\n",
    "        idx = (np.random.choice(samples.shape[0]))\n",
    "        v = samples[idx, :sl.ndim]\n",
    "        av = samples[idx, sl.ndim:2*sl.ndim]\n",
    "        av_scatter = samples[idx, 2*sl.ndim:]\n",
    "        davdd_all = av * np.ones((sl.nsig, sl.ndim)) + av_scatter.reshape((sl.nsig, sl.ndim))\n",
    "        model_signals = sl.model_signals(v, davdd_all)\n",
    "        return model_signals\n",
    "\n",
    "    model_signals = sl.model_signals(v, davdd_all)\n",
    "    print( model_signals.shape)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize = (10, 20))\n",
    "\n",
    "\n",
    "    order_inds = np.array(np.argsort(sl.stars['DIST']))\n",
    "    # signal_recreated, signal_recreated_unsummed = model_signals_thing(med_velo, sl, med_dAV_dd) \n",
    "    for i in range(len(order_inds)):\n",
    "        ii = order_inds[i]\n",
    "        # bindex = sl.bin_inds[ii]\n",
    "        # ax.plot(wavs_window, sl.signals[ii, :] + 0.05 * i, color = 'C{}'.format(i))\n",
    "        # ax.fill_between(wavs_window, sl.signals[ii, :] + sl.signal_errs[ii, :] + 0.05 * i,\n",
    "        #                  sl.signals[ii, :] - sl.signal_errs[ii, :] + 0.05 * i, color = 'C{}'.format(bindex), alpha = 0.1)\n",
    "\n",
    "\n",
    "        ax.plot(wavs[window], model_signals[ii, :] + 0.1 * i, color = 'C{}'.format(i))        \n",
    "        ax.plot(wavs[window], sl.signals[ii, :]+ 0.1 * i, color = 'C{}'.format(i))\n",
    "        for k in range(50):\n",
    "            ax.plot(wavs[window], sample_signal()[ii, :] + 0.1 * i, color = 'C{}'.format(i), alpha = 0.05)\n",
    "        ax.set_xlabel('Wavelength ($\\AA$)')\n",
    "        ax.set_ylabel('Flux + Offset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(sightlines)):\n",
    "    sl_i = sightlines[i]\n",
    "    chain = chains[i]\n",
    "    samples = chain[:, int(0.8 * chain.shape[1]), :]\n",
    "    # samples = sl_i.sampler.chain[:, int(0.8 * sampler.chain.shape[1]), :]\n",
    "\n",
    "    make_plots_sample(samples, sl_i, logprob = probabilities[i], chain = chains[i])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def velo_plots(sl, chain):\n",
    "    samples = chain[:, int(0.8 * chain.shape[1]), :]\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.violinplot(samples[:, :sl.ndim])\n",
    "    \n",
    "for i in range(len(sightlines)):\n",
    "    velo_plots(sightlines[i], chains[i])\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
